{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predikcia vybranych parametrov\n",
    "### Predikcia inclination, mass ratio, temperature ratio, potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Dense, concatenate, Activation, LSTM, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import Concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_observation_sigma(space_obs_frac=0.5):\n",
    "    \"\"\"\n",
    "    Draws a standard deviation of noise in light curve points from a \"true\" value provided in synthetic light curve.\n",
    "    Noise sigma is drawn from bimodal distribution taking into account contributions from space based and earth based\n",
    "    observations which have different levels of stochastic noise.\n",
    "\n",
    "    :param space_obs_frac: ratio between earth based and space based observations\n",
    "    :return: float; standard deviation of the light curve noise\n",
    "    \"\"\"\n",
    "    earth_based_sigma = 4e-3\n",
    "    space_based_sigma = 2e-4\n",
    "    sigma = np.random.choice([earth_based_sigma, space_based_sigma], p=[1-space_obs_frac, space_obs_frac])\n",
    "    return np.random.rayleigh(sigma)\n",
    "\n",
    "def stochastic_noise_generator(curve):\n",
    "    \"\"\"\n",
    "    Introduces gaussian noise into synthetic observation provided in `curve`.\n",
    "\n",
    "    :param curve: numpy.array; normalized light curve\n",
    "    :return: Tuple(numpy.array, float); normalized light curve with added noise, standard deviation of observations\n",
    "    \"\"\"\n",
    "    sigma = generate_observation_sigma()\n",
    "    return np.random.normal(curve, sigma), np.full(curve.shape, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"detached_all_parameters.pkl\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(n=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'id',\n",
       " 'curve',\n",
       " 'primary__t_eff',\n",
       " 'secondary__t_eff',\n",
       " 'inclination',\n",
       " 'mass_ratio',\n",
       " 'primary__surface_potential',\n",
       " 'secondary__surface_potential',\n",
       " 't1_t2',\n",
       " 'filter',\n",
       " 'critical_surface_potential',\n",
       " 'primary__equivalent_radius',\n",
       " 'secondary__equivalent_radius',\n",
       " 'primary__filling_factor',\n",
       " 'secondary__filling_factor']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for row in data_sample[\"curve\"]:\n",
    "    X.append(row)\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data_sample[[\n",
    "    \"inclination\",\n",
    "    \"mass_ratio\",\n",
    "    \"primary__surface_potential\",\n",
    "    \"secondary__surface_potential\",\n",
    "    \"t1_t2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71584635, 0.05050505, 0.17208073, 0.0020424 , 0.7804878 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMax Scaler\n",
    "scaler = MinMaxScaler()\n",
    "y_minmax_scaled = scaler.fit_transform(y)\n",
    "y_minmax_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y_minmax_scaled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to train data\n",
    "X_train_n = []\n",
    "y_train_n = []\n",
    "for i in range(len(X_train1)):\n",
    "    for j in range(3):\n",
    "        curve = stochastic_noise_generator(X_train1[i])\n",
    "        X_train_n.append(curve[0])\n",
    "        y_train_n.append(y_train1[i])\n",
    "X_train_n = np.array(X_train_n)\n",
    "y_train_n=np.array(y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in dataset:  1300000 \n",
      "Number of records in sample:  300000 \n",
      "Number of train data without noise:  240000 \n",
      "Number of train data with noise:  720000 \n",
      "Number of test data without noise:  60000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in dataset: \", len(data),\n",
    "    \"\\nNumber of records in sample: \", len(X),\n",
    "    \"\\nNumber of train data without noise: \", len(X_train1),\n",
    "    \"\\nNumber of train data with noise: \", len(X_train_n),\n",
    "    \"\\nNumber of test data without noise: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 400, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 199, 64)           33024     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12736)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                815168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 850,693\n",
      "Trainable params: 850,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(400, 1))\n",
    "b = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs)\n",
    "b = MaxPooling1D(2)(b)\n",
    "b = Dropout(0.2)(b)\n",
    "b = LSTM(64, return_sequences=True)(b)\n",
    "b = Flatten()(b)\n",
    "b = Dense(64, activation='relu')(b)\n",
    "x = Dense(32, activation='relu')(b)\n",
    "output = Dense(5, activation='linear')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mae\", \"mape\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = \"models/norm_detached_selection.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor = 'val_mae', verbose = 1, save_best_only = True, mode = 'min')\n",
    "early = EarlyStopping(monitor = \"val_mae\", mode = \"min\", patience = 25)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0219 - mae: 0.0849 - mape: 1863293.5000\n",
      "Epoch 00001: val_mae improved from inf to 0.07035, saving model to models\\norm_detached_selection.hdf5\n",
      "10125/10125 [==============================] - 1453s 144ms/step - loss: 0.0219 - mae: 0.0849 - mape: 1863293.5000 - val_loss: 0.0175 - val_mae: 0.0704 - val_mape: 1537172.8750\n",
      "Epoch 2/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0161 - mae: 0.0692 - mape: 1618475.2500\n",
      "Epoch 00002: val_mae improved from 0.07035 to 0.06169, saving model to models\\norm_detached_selection.hdf5\n",
      "10125/10125 [==============================] - 1381s 136ms/step - loss: 0.0161 - mae: 0.0692 - mape: 1618475.2500 - val_loss: 0.0143 - val_mae: 0.0617 - val_mape: 1402562.7500\n",
      "Epoch 3/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0144 - mae: 0.0639 - mape: 1570782.6250\n",
      "Epoch 00003: val_mae improved from 0.06169 to 0.06023, saving model to models\\norm_detached_selection.hdf5\n",
      "10125/10125 [==============================] - 1386s 137ms/step - loss: 0.0144 - mae: 0.0639 - mape: 1570782.6250 - val_loss: 0.0132 - val_mae: 0.0602 - val_mape: 1629412.3750\n",
      "Epoch 4/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0135 - mae: 0.0609 - mape: 1505465.0000\n",
      "Epoch 00004: val_mae improved from 0.06023 to 0.05767, saving model to models\\norm_detached_selection.hdf5\n",
      "10125/10125 [==============================] - 1386s 137ms/step - loss: 0.0135 - mae: 0.0609 - mape: 1505465.0000 - val_loss: 0.0123 - val_mae: 0.0577 - val_mape: 1455843.0000\n",
      "Epoch 5/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0129 - mae: 0.0590 - mape: 1446985.6250\n",
      "Epoch 00005: val_mae improved from 0.05767 to 0.05457, saving model to models\\norm_detached_selection.hdf5\n",
      "10125/10125 [==============================] - 1386s 137ms/step - loss: 0.0129 - mae: 0.0590 - mape: 1446985.6250 - val_loss: 0.0116 - val_mae: 0.0546 - val_mape: 1426126.6250\n",
      "Epoch 6/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0124 - mae: 0.0574 - mape: 1404109.3750\n",
      "Epoch 00006: val_mae did not improve from 0.05457\n",
      "10125/10125 [==============================] - 1396s 138ms/step - loss: 0.0124 - mae: 0.0574 - mape: 1404109.3750 - val_loss: 0.0117 - val_mae: 0.0546 - val_mape: 1293000.0000\n",
      "Epoch 7/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0120 - mae: 0.0560 - mape: 1360266.3750\n",
      "Epoch 00007: val_mae improved from 0.05457 to 0.05361, saving model to models\\norm_detached_selection.hdf5\n",
      "10125/10125 [==============================] - 1366s 135ms/step - loss: 0.0120 - mae: 0.0560 - mape: 1360266.3750 - val_loss: 0.0117 - val_mae: 0.0536 - val_mape: 1250495.3750\n",
      "Epoch 8/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0117 - mae: 0.0548 - mape: 1340149.7500\n",
      "Epoch 00008: val_mae improved from 0.05361 to 0.05269, saving model to models\\norm_detached_selection.hdf5\n",
      "10125/10125 [==============================] - 1373s 136ms/step - loss: 0.0117 - mae: 0.0548 - mape: 1340149.7500 - val_loss: 0.0110 - val_mae: 0.0527 - val_mape: 1362088.1250\n",
      "Epoch 9/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0114 - mae: 0.0538 - mape: 1302969.2500\n",
      "Epoch 00009: val_mae improved from 0.05269 to 0.05211, saving model to models\\norm_detached_selection.hdf5\n",
      "10125/10125 [==============================] - 1371s 135ms/step - loss: 0.0114 - mae: 0.0538 - mape: 1302969.2500 - val_loss: 0.0107 - val_mae: 0.0521 - val_mape: 1257343.8750\n",
      "Epoch 10/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0112 - mae: 0.0532 - mape: 1275234.5000\n",
      "Epoch 00010: val_mae improved from 0.05211 to 0.05057, saving model to models\\norm_detached_selection.hdf5\n",
      "10125/10125 [==============================] - 1375s 136ms/step - loss: 0.0112 - mae: 0.0532 - mape: 1275234.5000 - val_loss: 0.0104 - val_mae: 0.0506 - val_mape: 1275792.7500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_n, y_train_n, validation_split = 0.1, epochs = 10, verbose = 1, callbacks = callbacks_list, batch_size = 64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('global')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8fc6ce4f931e35f5dd2ff00f5d2ede33ff85432a244cf6e3e9d498f6426f487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
