{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predikcia vybranych parametrov\n",
    "### Overcontact\n",
    "### Predikcia inclination, mass ratio, temperature ratio, potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Dense, concatenate, Activation, LSTM, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import Concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_observation_sigma(space_obs_frac=0.5):\n",
    "    \"\"\"\n",
    "    Draws a standard deviation of noise in light curve points from a \"true\" value provided in synthetic light curve.\n",
    "    Noise sigma is drawn from bimodal distribution taking into account contributions from space based and earth based\n",
    "    observations which have different levels of stochastic noise.\n",
    "\n",
    "    :param space_obs_frac: ratio between earth based and space based observations\n",
    "    :return: float; standard deviation of the light curve noise\n",
    "    \"\"\"\n",
    "    earth_based_sigma = 4e-3\n",
    "    space_based_sigma = 2e-4\n",
    "    sigma = np.random.choice([earth_based_sigma, space_based_sigma], p=[1-space_obs_frac, space_obs_frac])\n",
    "    return np.random.rayleigh(sigma)\n",
    "\n",
    "def stochastic_noise_generator(curve):\n",
    "    \"\"\"\n",
    "    Introduces gaussian noise into synthetic observation provided in `curve`.\n",
    "\n",
    "    :param curve: numpy.array; normalized light curve\n",
    "    :return: Tuple(numpy.array, float); normalized light curve with added noise, standard deviation of observations\n",
    "    \"\"\"\n",
    "    sigma = generate_observation_sigma()\n",
    "    return np.random.normal(curve, sigma), np.full(curve.shape, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"overcontact_all_parameters.pkl\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(n=300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'id',\n",
       " 'curve',\n",
       " 'primary__t_eff',\n",
       " 'secondary__t_eff',\n",
       " 'inclination',\n",
       " 'mass_ratio',\n",
       " 'primary__surface_potential',\n",
       " 'secondary__surface_potential',\n",
       " 't1/t2',\n",
       " 'filter',\n",
       " 'critical_surface_potential',\n",
       " 'primary__equivalent_radius',\n",
       " 'secondary__equivalent_radius',\n",
       " 'primary__filling_factor',\n",
       " 'secondary__filling_factor']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_sample.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for row in data_sample[\"curve\"]:\n",
    "    X.append(row)\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data_sample[[\n",
    "    \"inclination\",\n",
    "    \"mass_ratio\",\n",
    "    \"primary__surface_potential\",\n",
    "    \"secondary__surface_potential\",\n",
    "    \"t1/t2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79148929, 0.49494949, 0.53031622, 0.53031622, 0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMax Scaler\n",
    "scaler = MinMaxScaler()\n",
    "y_minmax_scaled = scaler.fit_transform(y)\n",
    "y_minmax_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y_minmax_scaled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to train data\n",
    "X_train_n = []\n",
    "y_train_n = []\n",
    "for i in range(len(X_train1)):\n",
    "    for j in range(3):\n",
    "        curve = stochastic_noise_generator(X_train1[i])\n",
    "        X_train_n.append(curve[0])\n",
    "        y_train_n.append(y_train1[i])\n",
    "X_train_n = np.array(X_train_n)\n",
    "y_train_n=np.array(y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in dataset:  1212796 \n",
      "Number of records in sample:  300000 \n",
      "Number of train data without noise:  240000 \n",
      "Number of train data with noise:  720000 \n",
      "Number of test data without noise:  60000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in dataset: \", len(data),\n",
    "    \"\\nNumber of records in sample: \", len(X),\n",
    "    \"\\nNumber of train data without noise: \", len(X_train1),\n",
    "    \"\\nNumber of train data with noise: \", len(X_train_n),\n",
    "    \"\\nNumber of test data without noise: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 400, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 199, 64)           33024     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12736)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                815168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 850,693\n",
      "Trainable params: 850,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(400, 1))\n",
    "b = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs)\n",
    "b = MaxPooling1D(2)(b)\n",
    "b = Dropout(0.2)(b)\n",
    "b = LSTM(64, return_sequences=True)(b)\n",
    "b = Flatten()(b)\n",
    "b = Dense(64, activation='relu')(b)\n",
    "x = Dense(32, activation='relu')(b)\n",
    "output = Dense(5, activation='linear')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mae\", \"mape\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = \"models/norm_overcontact_selection.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor = 'val_mae', verbose = 1, save_best_only = True, mode = 'min')\n",
    "early = EarlyStopping(monitor = \"val_mae\", mode = \"min\", patience = 25)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0102 - mae: 0.0602 - mape: 7245895.0000\n",
      "Epoch 00001: val_mae improved from inf to 0.04150, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1669s 165ms/step - loss: 0.0102 - mae: 0.0602 - mape: 7245895.0000 - val_loss: 0.0056 - val_mae: 0.0415 - val_mape: 5226817.5000\n",
      "Epoch 2/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0063 - mae: 0.0459 - mape: 5063508.5000\n",
      "Epoch 00002: val_mae improved from 0.04150 to 0.03797, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1461s 144ms/step - loss: 0.0063 - mae: 0.0459 - mape: 5063508.5000 - val_loss: 0.0048 - val_mae: 0.0380 - val_mape: 4130595.2500\n",
      "Epoch 3/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0058 - mae: 0.0430 - mape: 4662523.5000\n",
      "Epoch 00003: val_mae improved from 0.03797 to 0.03612, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1197s 118ms/step - loss: 0.0058 - mae: 0.0430 - mape: 4662523.5000 - val_loss: 0.0047 - val_mae: 0.0361 - val_mape: 3429707.7500\n",
      "Epoch 4/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0055 - mae: 0.0413 - mape: 4466712.0000\n",
      "Epoch 00004: val_mae did not improve from 0.03612\n",
      "10125/10125 [==============================] - 1207s 119ms/step - loss: 0.0055 - mae: 0.0413 - mape: 4466712.0000 - val_loss: 0.0045 - val_mae: 0.0378 - val_mape: 4276660.0000\n",
      "Epoch 5/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0052 - mae: 0.0400 - mape: 4336098.0000\n",
      "Epoch 00005: val_mae improved from 0.03612 to 0.03433, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1271s 126ms/step - loss: 0.0052 - mae: 0.0400 - mape: 4336098.0000 - val_loss: 0.0043 - val_mae: 0.0343 - val_mape: 3821489.7500\n",
      "Epoch 6/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0050 - mae: 0.0389 - mape: 4197752.5000\n",
      "Epoch 00006: val_mae did not improve from 0.03433\n",
      "10125/10125 [==============================] - 1252s 124ms/step - loss: 0.0050 - mae: 0.0389 - mape: 4197752.5000 - val_loss: 0.0042 - val_mae: 0.0349 - val_mape: 3935021.2500\n",
      "Epoch 7/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0049 - mae: 0.0382 - mape: 4117690.0000\n",
      "Epoch 00007: val_mae improved from 0.03433 to 0.03414, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1265s 125ms/step - loss: 0.0049 - mae: 0.0382 - mape: 4117690.0000 - val_loss: 0.0041 - val_mae: 0.0341 - val_mape: 4133843.5000\n",
      "Epoch 8/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0048 - mae: 0.0376 - mape: 4034764.7500\n",
      "Epoch 00008: val_mae did not improve from 0.03414\n",
      "10125/10125 [==============================] - 1270s 125ms/step - loss: 0.0048 - mae: 0.0376 - mape: 4034764.7500 - val_loss: 0.0044 - val_mae: 0.0377 - val_mape: 3248022.7500\n",
      "Epoch 9/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0047 - mae: 0.0371 - mape: 3935298.0000\n",
      "Epoch 00009: val_mae did not improve from 0.03414\n",
      "10125/10125 [==============================] - 1253s 124ms/step - loss: 0.0047 - mae: 0.0371 - mape: 3935298.0000 - val_loss: 0.0040 - val_mae: 0.0343 - val_mape: 3873350.0000\n",
      "Epoch 10/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0046 - mae: 0.0367 - mape: 3882957.5000\n",
      "Epoch 00010: val_mae improved from 0.03414 to 0.03358, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1268s 125ms/step - loss: 0.0046 - mae: 0.0367 - mape: 3882957.5000 - val_loss: 0.0040 - val_mae: 0.0336 - val_mape: 2996968.2500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_n, y_train_n, validation_split = 0.1, epochs = 10, verbose = 1, callbacks = callbacks_list, batch_size = 64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('global')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8fc6ce4f931e35f5dd2ff00f5d2ede33ff85432a244cf6e3e9d498f6426f487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
