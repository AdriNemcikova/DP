{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predikcia vsetkych parametrov pomocou jednej NN pre normovane oovercontact data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Dense, concatenate, Activation, LSTM, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import Concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_observation_sigma(space_obs_frac=0.5):\n",
    "    \"\"\"\n",
    "    Draws a standard deviation of noise in light curve points from a \"true\" value provided in synthetic light curve.\n",
    "    Noise sigma is drawn from bimodal distribution taking into account contributions from space based and earth based\n",
    "    observations which have different levels of stochastic noise.\n",
    "\n",
    "    :param space_obs_frac: ratio between earth based and space based observations\n",
    "    :return: float; standard deviation of the light curve noise\n",
    "    \"\"\"\n",
    "    earth_based_sigma = 4e-3\n",
    "    space_based_sigma = 2e-4\n",
    "    sigma = np.random.choice([earth_based_sigma, space_based_sigma], p=[1-space_obs_frac, space_obs_frac])\n",
    "    return np.random.rayleigh(sigma)\n",
    "\n",
    "def stochastic_noise_generator(curve):\n",
    "    \"\"\"\n",
    "    Introduces gaussian noise into synthetic observation provided in `curve`.\n",
    "\n",
    "    :param curve: numpy.array; normalized light curve\n",
    "    :return: Tuple(numpy.array, float); normalized light curve with added noise, standard deviation of observations\n",
    "    \"\"\"\n",
    "    sigma = generate_observation_sigma()\n",
    "    return np.random.normal(curve, sigma), np.full(curve.shape, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"overcontact_all_parameters.pkl\").reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>curve</th>\n",
       "      <th>primary__t_eff</th>\n",
       "      <th>secondary__t_eff</th>\n",
       "      <th>inclination</th>\n",
       "      <th>mass_ratio</th>\n",
       "      <th>primary__surface_potential</th>\n",
       "      <th>secondary__surface_potential</th>\n",
       "      <th>t1/t2</th>\n",
       "      <th>filter</th>\n",
       "      <th>critical_surface_potential</th>\n",
       "      <th>primary__equivalent_radius</th>\n",
       "      <th>secondary__equivalent_radius</th>\n",
       "      <th>primary__filling_factor</th>\n",
       "      <th>secondary__filling_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5525038</td>\n",
       "      <td>[0.9271109336686163, 0.9271335908185164, 0.927...</td>\n",
       "      <td>5500</td>\n",
       "      <td>5250</td>\n",
       "      <td>0.766994</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>1.047619</td>\n",
       "      <td>Bessell_U</td>\n",
       "      <td>1.959104</td>\n",
       "      <td>0.585781</td>\n",
       "      <td>0.21126</td>\n",
       "      <td>0.169244</td>\n",
       "      <td>0.169244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5525038</td>\n",
       "      <td>[0.9267426667358384, 0.9267640025030627, 0.926...</td>\n",
       "      <td>5500</td>\n",
       "      <td>5250</td>\n",
       "      <td>0.766994</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>1.047619</td>\n",
       "      <td>Bessell_B</td>\n",
       "      <td>1.959104</td>\n",
       "      <td>0.585781</td>\n",
       "      <td>0.21126</td>\n",
       "      <td>0.169244</td>\n",
       "      <td>0.169244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5525038</td>\n",
       "      <td>[0.9271736551553694, 0.927193188167849, 0.9272...</td>\n",
       "      <td>5500</td>\n",
       "      <td>5250</td>\n",
       "      <td>0.766994</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>1.047619</td>\n",
       "      <td>Bessell_V</td>\n",
       "      <td>1.959104</td>\n",
       "      <td>0.585781</td>\n",
       "      <td>0.21126</td>\n",
       "      <td>0.169244</td>\n",
       "      <td>0.169244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5525038</td>\n",
       "      <td>[0.9286697051715368, 0.9286879105609007, 0.928...</td>\n",
       "      <td>5500</td>\n",
       "      <td>5250</td>\n",
       "      <td>0.766994</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>1.047619</td>\n",
       "      <td>Bessell_R</td>\n",
       "      <td>1.959104</td>\n",
       "      <td>0.585781</td>\n",
       "      <td>0.21126</td>\n",
       "      <td>0.169244</td>\n",
       "      <td>0.169244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5525038</td>\n",
       "      <td>[0.9304596200748534, 0.9304764401089076, 0.930...</td>\n",
       "      <td>5500</td>\n",
       "      <td>5250</td>\n",
       "      <td>0.766994</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>1.948052</td>\n",
       "      <td>1.047619</td>\n",
       "      <td>Bessell_I</td>\n",
       "      <td>1.959104</td>\n",
       "      <td>0.585781</td>\n",
       "      <td>0.21126</td>\n",
       "      <td>0.169244</td>\n",
       "      <td>0.169244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       id                                              curve  \\\n",
       "0      0  5525038  [0.9271109336686163, 0.9271335908185164, 0.927...   \n",
       "1      1  5525038  [0.9267426667358384, 0.9267640025030627, 0.926...   \n",
       "2      2  5525038  [0.9271736551553694, 0.927193188167849, 0.9272...   \n",
       "3      3  5525038  [0.9286697051715368, 0.9286879105609007, 0.928...   \n",
       "4      4  5525038  [0.9304596200748534, 0.9304764401089076, 0.930...   \n",
       "\n",
       "   primary__t_eff  secondary__t_eff  inclination  mass_ratio  \\\n",
       "0            5500              5250     0.766994         0.1   \n",
       "1            5500              5250     0.766994         0.1   \n",
       "2            5500              5250     0.766994         0.1   \n",
       "3            5500              5250     0.766994         0.1   \n",
       "4            5500              5250     0.766994         0.1   \n",
       "\n",
       "   primary__surface_potential  secondary__surface_potential     t1/t2  \\\n",
       "0                    1.948052                      1.948052  1.047619   \n",
       "1                    1.948052                      1.948052  1.047619   \n",
       "2                    1.948052                      1.948052  1.047619   \n",
       "3                    1.948052                      1.948052  1.047619   \n",
       "4                    1.948052                      1.948052  1.047619   \n",
       "\n",
       "      filter  critical_surface_potential  primary__equivalent_radius  \\\n",
       "0  Bessell_U                    1.959104                    0.585781   \n",
       "1  Bessell_B                    1.959104                    0.585781   \n",
       "2  Bessell_V                    1.959104                    0.585781   \n",
       "3  Bessell_R                    1.959104                    0.585781   \n",
       "4  Bessell_I                    1.959104                    0.585781   \n",
       "\n",
       "   secondary__equivalent_radius  primary__filling_factor  \\\n",
       "0                       0.21126                 0.169244   \n",
       "1                       0.21126                 0.169244   \n",
       "2                       0.21126                 0.169244   \n",
       "3                       0.21126                 0.169244   \n",
       "4                       0.21126                 0.169244   \n",
       "\n",
       "   secondary__filling_factor  \n",
       "0                   0.169244  \n",
       "1                   0.169244  \n",
       "2                   0.169244  \n",
       "3                   0.169244  \n",
       "4                   0.169244  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'id',\n",
       " 'curve',\n",
       " 'primary__t_eff',\n",
       " 'secondary__t_eff',\n",
       " 'inclination',\n",
       " 'mass_ratio',\n",
       " 'primary__surface_potential',\n",
       " 'secondary__surface_potential',\n",
       " 't1/t2',\n",
       " 'filter',\n",
       " 'critical_surface_potential',\n",
       " 'primary__equivalent_radius',\n",
       " 'secondary__equivalent_radius',\n",
       " 'primary__filling_factor',\n",
       " 'secondary__filling_factor']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_sample.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split + Normalizacia y_train na interval <0,1> pomocou sklearn - MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for row in data_sample[\"curve\"]:\n",
    "    X.append(row)\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data_sample[[\n",
    "    \"primary__t_eff\",\n",
    "    \"secondary__t_eff\",\n",
    "    \"inclination\",\n",
    "    \"mass_ratio\",\n",
    "    \"primary__surface_potential\",\n",
    "    \"secondary__surface_potential\",\n",
    "    \"t1/t2\",\n",
    "    \"critical_surface_potential\",\n",
    "    \"primary__equivalent_radius\",\n",
    "    \"secondary__equivalent_radius\",\n",
    "    \"primary__filling_factor\",\n",
    "    \"secondary__filling_factor\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.25000000e+03, 7.25000000e+03, 1.34646754e+00, 5.00000000e+00,\n",
       "       8.84280105e+00, 8.84280105e+00, 1.00000000e+00, 9.16363872e+00,\n",
       "       2.76515706e-01, 5.46146250e-01, 5.02919516e-01, 5.02919516e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "y_normed = scaler.fit_transform(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73333333, 0.6       , 0.86744652, 0.07070707, 0.11033009,\n",
       "       0.11033009, 0.65384615, 0.1110169 , 0.51395182, 0.41372501,\n",
       "       0.11237215, 0.11237215])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_normed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(len(X_train1)):\n",
    "    for j in range(3):\n",
    "        curve = stochastic_noise_generator(X_train1[i])\n",
    "        X_train.append(curve[0])\n",
    "        y_train.append(y_normed[i])\n",
    "X_train = np.array(X_train)\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in dataset:  1212796 \n",
      "Number of records in sample:  100000 \n",
      "Number of train data without noise:  80000 \n",
      "Number of train data with noise:  240000 \n",
      "Number of test data without noise:  20000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in dataset: \", len(data),\n",
    "    \"\\nNumber of records in sample: \", len(X),\n",
    "    \"\\nNumber of train data without noise: \", len(X_train1),\n",
    "    \"\\nNumber of train data with noise: \", len(X_train),\n",
    "    \"\\nNumber of test data without noise: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 400, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 199, 64)           33024     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12736)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                815168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 850,924\n",
      "Trainable params: 850,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(400, 1))\n",
    "b = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs)\n",
    "b = MaxPooling1D(2)(b)\n",
    "b = Dropout(0.2)(b)\n",
    "b = LSTM(64, return_sequences=True)(b)\n",
    "b = Flatten()(b)\n",
    "b = Dense(64, activation='relu')(b)\n",
    "x = Dense(32, activation='relu')(b)\n",
    "output = Dense(12, activation='linear')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mae\", \"mape\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = \"models/norm_over_allParams.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor = 'val_mae', verbose = 1, save_best_only = True, mode = 'min')\n",
    "early = EarlyStopping(monitor = \"val_mae\", mode = \"min\", patience = 25)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0267 - mae: 0.1132 - mape: 5716561.5000\n",
      "Epoch 00001: val_mae improved from inf to 0.09177, saving model to models\\norm_over_allParams.hdf5\n",
      "3375/3375 [==============================] - 636s 188ms/step - loss: 0.0267 - mae: 0.1132 - mape: 5716561.5000 - val_loss: 0.0189 - val_mae: 0.0918 - val_mape: 5107174.5000\n",
      "Epoch 2/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0175 - mae: 0.0876 - mape: 3737979.0000\n",
      "Epoch 00002: val_mae improved from 0.09177 to 0.08039, saving model to models\\norm_over_allParams.hdf5\n",
      "3375/3375 [==============================] - 618s 183ms/step - loss: 0.0175 - mae: 0.0876 - mape: 3737979.0000 - val_loss: 0.0157 - val_mae: 0.0804 - val_mape: 2806076.5000\n",
      "Epoch 3/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0160 - mae: 0.0821 - mape: 3402996.7500 ETA: 3s - loss: 0\n",
      "Epoch 00003: val_mae improved from 0.08039 to 0.07494, saving model to models\\norm_over_allParams.hdf5\n",
      "3375/3375 [==============================] - 633s 188ms/step - loss: 0.0160 - mae: 0.0821 - mape: 3402996.7500 - val_loss: 0.0142 - val_mae: 0.0749 - val_mape: 3679818.0000\n",
      "Epoch 4/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0153 - mae: 0.0793 - mape: 3218362.7500\n",
      "Epoch 00004: val_mae did not improve from 0.07494\n",
      "3375/3375 [==============================] - 606s 180ms/step - loss: 0.0153 - mae: 0.0793 - mape: 3218362.7500 - val_loss: 0.0157 - val_mae: 0.0782 - val_mape: 2803433.7500\n",
      "Epoch 5/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0149 - mae: 0.0775 - mape: 3104641.5000\n",
      "Epoch 00005: val_mae improved from 0.07494 to 0.07126, saving model to models\\norm_over_allParams.hdf5\n",
      "3375/3375 [==============================] - 556s 165ms/step - loss: 0.0149 - mae: 0.0775 - mape: 3104641.5000 - val_loss: 0.0132 - val_mae: 0.0713 - val_mape: 2669989.5000\n",
      "Epoch 6/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0145 - mae: 0.0762 - mape: 3011431.0000\n",
      "Epoch 00006: val_mae improved from 0.07126 to 0.07086, saving model to models\\norm_over_allParams.hdf5\n",
      "3375/3375 [==============================] - 544s 161ms/step - loss: 0.0145 - mae: 0.0762 - mape: 3011431.0000 - val_loss: 0.0134 - val_mae: 0.0709 - val_mape: 2594160.7500\n",
      "Epoch 7/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0143 - mae: 0.0752 - mape: 2932369.0000\n",
      "Epoch 00007: val_mae improved from 0.07086 to 0.06757, saving model to models\\norm_over_allParams.hdf5\n",
      "3375/3375 [==============================] - 544s 161ms/step - loss: 0.0143 - mae: 0.0752 - mape: 2932369.0000 - val_loss: 0.0126 - val_mae: 0.0676 - val_mape: 2664365.2500\n",
      "Epoch 8/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0141 - mae: 0.0744 - mape: 2871786.0000\n",
      "Epoch 00008: val_mae did not improve from 0.06757\n",
      "3375/3375 [==============================] - 537s 159ms/step - loss: 0.0141 - mae: 0.0744 - mape: 2871786.0000 - val_loss: 0.0126 - val_mae: 0.0684 - val_mape: 2328475.2500\n",
      "Epoch 9/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0139 - mae: 0.0737 - mape: 2816106.5000\n",
      "Epoch 00009: val_mae did not improve from 0.06757\n",
      "3375/3375 [==============================] - 556s 165ms/step - loss: 0.0139 - mae: 0.0737 - mape: 2816106.5000 - val_loss: 0.0127 - val_mae: 0.0711 - val_mape: 2376511.5000\n",
      "Epoch 10/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0136 - mae: 0.0727 - mape: 2753439.0000\n",
      "Epoch 00010: val_mae improved from 0.06757 to 0.06679, saving model to models\\norm_over_allParams.hdf5\n",
      "3375/3375 [==============================] - 551s 163ms/step - loss: 0.0136 - mae: 0.0727 - mape: 2753439.0000 - val_loss: 0.0122 - val_mae: 0.0668 - val_mape: 2679002.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split = 0.1, epochs = 10, verbose = 1, callbacks = callbacks_list, batch_size = 64)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8fc6ce4f931e35f5dd2ff00f5d2ede33ff85432a244cf6e3e9d498f6426f487"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('global')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
