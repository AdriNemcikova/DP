{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyza citlivosti\n",
    "Posunutie hodnot predikcii k 1. vyssej hodnote, 2. vyssej hodnote a 1. nizsej hodnote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 1\n",
    "# Nacitanie kniznic a nastavenie seed a zobrazovania riadkov\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import load_model\n",
    "from ast import literal_eval\n",
    "\n",
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 2\n",
    "# Nacitanie model na individualnu predikciu parametrov\n",
    "det_inc = load_model(\"models/detached_inclination.hdf5\")        # inclination\n",
    "det_q = load_model(\"models/detached_mass_ratio.hdf5\")           # mass ratio\n",
    "det_omega1 = load_model(\"models/detached_pSP.hdf5\")             # primary surface potential\n",
    "det_omega2 = load_model(\"models/detached_sSP.hdf5\")             # secondary surface potential\n",
    "det_temp = load_model(\"models/detached_t1_t2.hdf5\")             # temperature ratio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blok 3\n",
    "# Zadefinovanie funkcie pre vytvorenie dat na plotovanie zo samostatnych modelov\n",
    "# Data obsahujuce true hodnoty a originalne hodnoty predikcie\n",
    "def make_prediction_original(df, name_of_df, model_inc, model_q, model_omega1, model_omega2, model_temp):\n",
    "    # vytvorenie pola kriviek\n",
    "    X = []\n",
    "    for row in df[\"curve\"]:\n",
    "        X.append(row)\n",
    "    X = np.array(X)\n",
    "\n",
    "    # predikcia\n",
    "    pred_inc = model_inc.predict(X).flatten()\n",
    "    pred_q = model_q.predict(X).flatten()\n",
    "    pred_pp = model_omega1.predict(X).flatten()\n",
    "    pred_sp = model_omega2.predict(X).flatten()\n",
    "    pred_tr = model_temp.predict(X).flatten()\n",
    "\n",
    "    # vytvorenie vysledneho df predikcii\n",
    "    df['pred_inc']=pred_inc\n",
    "    df['pred_q']=pred_q\n",
    "    df['pred_omega1']=pred_pp\n",
    "    df['pred_omega2']=pred_sp\n",
    "    df['pred_t1_t2']=pred_tr\n",
    "\n",
    "    df.to_csv(f'Detached_sensitivity_analysis/true/{name_of_df}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>curve</th>\n",
       "      <th>primary__t_eff</th>\n",
       "      <th>secondary__t_eff</th>\n",
       "      <th>inclination</th>\n",
       "      <th>mass_ratio</th>\n",
       "      <th>primary__surface_potential</th>\n",
       "      <th>secondary__surface_potential</th>\n",
       "      <th>t1_t2</th>\n",
       "      <th>filter</th>\n",
       "      <th>critical_surface_potential</th>\n",
       "      <th>primary__equivalent_radius</th>\n",
       "      <th>secondary__equivalent_radius</th>\n",
       "      <th>primary__filling_factor</th>\n",
       "      <th>secondary__filling_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6055271686415179, 0.9842041250556204, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_U</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.608985656265516, 0.9846965713304289, 0.9998...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_B</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6189025614226916, 0.9837351924934223, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_V</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6292771409565273, 0.9832675811171884, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_R</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6543378609145588, 0.9835188424579704, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_I</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id                                              curve  \\\n",
       "0      0  38  [0.6055271686415179, 0.9842041250556204, 0.999...   \n",
       "1      1  38  [0.608985656265516, 0.9846965713304289, 0.9998...   \n",
       "2      2  38  [0.6189025614226916, 0.9837351924934223, 0.999...   \n",
       "3      3  38  [0.6292771409565273, 0.9832675811171884, 0.999...   \n",
       "4      4  38  [0.6543378609145588, 0.9835188424579704, 0.999...   \n",
       "\n",
       "   primary__t_eff  secondary__t_eff  inclination  mass_ratio  \\\n",
       "0            7000              4000     1.560796        10.0   \n",
       "1            7000              4000     1.560796        10.0   \n",
       "2            7000              4000     1.560796        10.0   \n",
       "3            7000              4000     1.560796        10.0   \n",
       "4            7000              4000     1.560796        10.0   \n",
       "\n",
       "   primary__surface_potential  secondary__surface_potential  t1_t2     filter  \\\n",
       "0                   110.00005                      996.5005   1.75  Bessell_U   \n",
       "1                   110.00005                      996.5005   1.75  Bessell_B   \n",
       "2                   110.00005                      996.5005   1.75  Bessell_V   \n",
       "3                   110.00005                      996.5005   1.75  Bessell_R   \n",
       "4                   110.00005                      996.5005   1.75  Bessell_I   \n",
       "\n",
       "   critical_surface_potential  primary__equivalent_radius  \\\n",
       "0                    15.09104                    0.009996   \n",
       "1                    15.09104                    0.009996   \n",
       "2                    15.09104                    0.009996   \n",
       "3                    15.09104                    0.009996   \n",
       "4                    15.09104                    0.009996   \n",
       "\n",
       "   secondary__equivalent_radius  primary__filling_factor  \\\n",
       "0                      0.009996              -145.333979   \n",
       "1                      0.009996              -145.333979   \n",
       "2                      0.009996              -145.333979   \n",
       "3                      0.009996              -145.333979   \n",
       "4                      0.009996              -145.333979   \n",
       "\n",
       "   secondary__filling_factor  \n",
       "0               -1502.830354  \n",
       "1               -1502.830354  \n",
       "2               -1502.830354  \n",
       "3               -1502.830354  \n",
       "4               -1502.830354  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Blok 4\n",
    "# Nacitanie dat\n",
    "data = pd.read_pickle(\"detached_all_parameters.pkl\").reset_index()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 5\n",
    "# Najdenie unikatnych hodnot v parametroch inclination, mass ratio, primary potential, secondary potential a pomertu teplot z povodnych dat\n",
    "# Unikatne hodnoty pre posun smerom hore, zoradene vzostupne\n",
    "inc_set_up, q_set_up, omega1_set_up, omega2_set_up, t1_t2_set_up = [], [], [], [], []\n",
    "\n",
    "for col in data:\n",
    "    if col == \"inclination\":\n",
    "        inc_set_up = sorted(list(set(data[col])))\n",
    "    if col == \"mass_ratio\":\n",
    "        q_set_up = sorted(list(set(data[col])))\n",
    "    if col == \"primary__surface_potential\":\n",
    "        omega1_set_up = sorted(list(set(data[col])))\n",
    "    if col == \"secondary__surface_potential\":\n",
    "        omega2_set_up = sorted(list(set(data[col])))\n",
    "    if col == \"t1_t2\":\n",
    "        t1_t2_set_up = sorted(list(set(data[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 6\n",
    "# Najdenie unikatnych hodnot v parametroch inclination, mass ratio, primary potential, secondary potential a pomertu teplot z povodnych dat\n",
    "#Unikatne hodnoty pre posun smerom dole, zoradene zostupne\n",
    "inc_set_down, q_set_down, omega1_set_down, omega2_set_down, t1_t2_set_down = [], [], [], [], []\n",
    "\n",
    "for col in data:\n",
    "    if col == \"inclination\":\n",
    "        inc_set_down = sorted(list(set(data[col])), reverse=True)\n",
    "    if col == \"mass_ratio\":\n",
    "        q_set_down = sorted(list(set(data[col])), reverse=True)\n",
    "    if col == \"primary__surface_potential\":\n",
    "        omega1_set_down = sorted(list(set(data[col])), reverse=True)\n",
    "    if col == \"secondary__surface_potential\":\n",
    "        omega2_set_down = sorted(list(set(data[col])), reverse=True)\n",
    "    if col == \"t1_t2\":\n",
    "        t1_t2_set_down = sorted(list(set(data[col])), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 7\n",
    "# Rozdelenie dat podla filtrov o vzorke 100 kriviek\n",
    "data_to_predict = data[[\"id\", \"curve\", \"filter\", \"inclination\", \"mass_ratio\", \"primary__surface_potential\", \"secondary__surface_potential\", \"t1_t2\"]]\n",
    "data_Bessel_U = data_to_predict[data_to_predict[\"filter\"] == \"Bessell_U\"].sample(100)\n",
    "data_Bessell_B = data_to_predict[data_to_predict[\"filter\"] == \"Bessell_B\"].sample(100)\n",
    "data_Bessell_V = data_to_predict[data_to_predict[\"filter\"] == \"Bessell_V\"].sample(100)\n",
    "data_Bessell_R = data_to_predict[data_to_predict[\"filter\"] == \"Bessell_R\"].sample(100)\n",
    "data_Bessell_I = data_to_predict[data_to_predict[\"filter\"] == \"Bessell_I\"].sample(100)\n",
    "data_SLOAN_u = data_to_predict[data_to_predict[\"filter\"] == \"SLOAN_u\"].sample(100)\n",
    "data_SLOAN_g = data_to_predict[data_to_predict[\"filter\"] == \"SLOAN_g\"].sample(100)\n",
    "data_SLOAN_r = data_to_predict[data_to_predict[\"filter\"] == \"SLOAN_r\"].sample(100)\n",
    "data_SLOAN_i = data_to_predict[data_to_predict[\"filter\"] == \"SLOAN_i\"].sample(100)\n",
    "data_SLOAN_z = data_to_predict[data_to_predict[\"filter\"] == \"SLOAN_z\"].sample(100)\n",
    "data_Kepler = data_to_predict[data_to_predict[\"filter\"] == \"Kepler\"].sample(100)\n",
    "data_GaiaDR2 = data_to_predict[data_to_predict[\"filter\"] == \"GaiaDR2\"].sample(100)\n",
    "data_tess = data_to_predict[data_to_predict[\"filter\"] == \"TESS\"].sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 8\n",
    "# Pouzitie funkcie make_prediction_original na vytvorenie predikcii pre kazdy filter\n",
    "make_prediction_original(data_Bessel_U, \"orig_det_data_Bessell_U\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_Bessell_B, \"orig_det_data_Bessell_B\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_Bessell_V, \"orig_det_data_Bessell_V\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_Bessell_R, \"orig_det_data_Bessell_R\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_Bessell_I, \"orig_det_data_Bessell_I\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_SLOAN_u, \"orig_det_data_SLOAN_u\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_SLOAN_g, \"orig_det_data_SLOAN_g\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_SLOAN_r, \"orig_det_data_SLOAN_r\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_SLOAN_i, \"orig_det_data_SLOAN_i\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_SLOAN_z, \"orig_det_data_SLOAN_z\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_Kepler, \"orig_det_data_Kepler\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_GaiaDR2, \"orig_det_data_GaiaDR2\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_tess, \"orig_det_data_TESS\", det_inc, det_q, det_omega1, det_omega2, det_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vytvorenie predikcii posunutych o 1 hodnotu vyssie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 9\n",
    "# Zadefinovanie funkcie, ktora najde prvu vyssiu hodnotu v zozname unikatnych hodnot pre kazdy parameter\n",
    "\n",
    "def find_value_one_up(prediction, unique_values):\n",
    "    for j in range(len(unique_values)):\n",
    "        if unique_values[j] > prediction:\n",
    "            prediction = unique_values[j]\n",
    "            break\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 10\n",
    "# funkcia pre vytvorenie dat na plotovanie zo samostatnych modelov a posun hodnot predikcii na 1. vyssiu  hodnotu zo zoznamu unikatnych hodnot\n",
    "def make_prediction_one_up(df, name_of_df,  model_inc, model_q, model_omega1, model_omega2, model_temp):\n",
    "    # vytvorenie pola kriviek\n",
    "    X = []\n",
    "    for row in df[\"curve\"]:\n",
    "        X.append(row)\n",
    "    X = np.array(X)\n",
    "\n",
    "    # predikcia\n",
    "    pred_inc = model_inc.predict(X).flatten()\n",
    "    pred_q = model_q.predict(X).flatten()\n",
    "    pred_pp = model_omega1.predict(X).flatten()\n",
    "    pred_sp = model_omega2.predict(X).flatten()\n",
    "    pred_tr = model_temp.predict(X).flatten()\n",
    "\n",
    "    df['pred_inc']=pred_inc\n",
    "    df['pred_q']=pred_q\n",
    "    df['pred_omega1']=pred_pp\n",
    "    df['pred_omega2']=pred_sp\n",
    "    df['pred_t1_t2']=pred_tr\n",
    "\n",
    "    new_preds_inc, new_preds_q, new_preds_omega1, new_preds_omega2, new_preds_t1_t2 = [], [], [], [], []\n",
    "\n",
    "    for i in df[\"pred_inc\"]:\n",
    "        new_preds_inc.append(find_value_one_up(i, inc_set_up))\n",
    "    df['pred_inc'] = new_preds_inc\n",
    "\n",
    "    for i in df[\"pred_q\"]:\n",
    "        new_preds_q.append(find_value_one_up(i, q_set_up))\n",
    "    df['pred_q'] = new_preds_q\n",
    "\n",
    "    for i in df[\"pred_omega1\"]:\n",
    "        new_preds_omega1.append(find_value_one_up(i, omega1_set_up))\n",
    "    df['pred_omega1'] = new_preds_omega1\n",
    "\n",
    "    for i in df[\"pred_omega2\"]:\n",
    "        new_preds_omega2.append(find_value_one_up(i, omega2_set_up))\n",
    "    df['pred_omega2'] = new_preds_omega2\n",
    "\n",
    "    for i in df[\"pred_t1_t2\"]:\n",
    "        new_preds_t1_t2.append(find_value_one_up(i, t1_t2_set_up))\n",
    "    df['pred_t1_t2'] = new_preds_t1_t2\n",
    "\n",
    "    df.to_csv(f'Detached_sensitivity_analysis/shift_1_up/{name_of_df}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 11\n",
    "# Vytvorenie upravenych predikcii\n",
    "make_prediction_one_up(data_Bessel_U, \"pred_1_up_det_data_Bessell_U\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_Bessell_B, \"pred_1_up_det_data_Bessell_B\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_Bessell_V, \"pred_1_up_det_data_Bessell_V\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_Bessell_R, \"pred_1_up_det_data_Bessell_R\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_Bessell_I, \"pred_1_up_det_data_Bessell_I\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_SLOAN_u, \"pred_1_up_det_data_SLOAN_u\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_SLOAN_g, \"pred_1_up_det_data_SLOAN_g\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_SLOAN_r, \"pred_1_up_det_data_SLOAN_r\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_SLOAN_i, \"pred_1_up_det_data_SLOAN_i\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_SLOAN_z, \"pred_1_up_det_data_SLOAN_z\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_Kepler, \"pred_1_up_det_data_Kepler\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_GaiaDR2, \"pred_1_up_det_data_GaiaDR2\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_tess, \"pred_1_up_det_data_TESS\", det_inc, det_q, det_omega1, det_omega2, det_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vytvorenie predikcii posunutych o 2 hodnoty vyssie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 12\n",
    "# Zadefinovanie funkcie, ktora najde druhu vyssiu hodnotu v zozname unikatnych hodnot pre kazdy parameter\n",
    "def find_value_two_up(prediction, unique_values):\n",
    "    for j in range(len(unique_values)):\n",
    "        if prediction < unique_values[j] and j+1 > len(unique_values)-1:\n",
    "            prediction = max(unique_values)\n",
    "            break\n",
    "        elif prediction < unique_values[j]:\n",
    "            prediction = unique_values[j+1]\n",
    "            break\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 13\n",
    "# funkcia pre vytvorenie dat na plotovanie zo samostatnych modelov a posun hodnot predikcii na 2. vyssiu  hodnotu zo zoznamu unikatnych hodnot\n",
    "def make_prediction_two_up(df, name_of_df, model_inc, model_q, model_omega1, model_omega2, model_temp):\n",
    "    # vytvorenie pola kriviek\n",
    "    X = []\n",
    "    for row in df[\"curve\"]:\n",
    "        X.append(row)\n",
    "    X = np.array(X)\n",
    "\n",
    "    # predikcia\n",
    "    pred_inc = model_inc.predict(X).flatten()\n",
    "    pred_q = model_q.predict(X).flatten()\n",
    "    pred_pp = model_omega1.predict(X).flatten()\n",
    "    pred_sp = model_omega2.predict(X).flatten()\n",
    "    pred_tr = model_temp.predict(X).flatten()\n",
    "\n",
    "    df['pred_inc']=pred_inc\n",
    "    df['pred_q']=pred_q\n",
    "    df['pred_omega1']=pred_pp\n",
    "    df['pred_omega2']=pred_sp\n",
    "    df['pred_t1_t2']=pred_tr\n",
    "\n",
    "    new_preds_inc, new_preds_q, new_preds_omega1, new_preds_omega2, new_preds_t1_t2 = [], [], [], [], []\n",
    "\n",
    "    for i in df[\"pred_inc\"]:\n",
    "        new_preds_inc.append(find_value_two_up(i, inc_set_up))\n",
    "    df['pred_inc'] = new_preds_inc\n",
    "\n",
    "    for i in df[\"pred_q\"]:\n",
    "        new_preds_q.append(find_value_two_up(i, q_set_up))\n",
    "    df['pred_q'] = new_preds_q\n",
    "\n",
    "    for i in df[\"pred_omega1\"]:\n",
    "        new_preds_omega1.append(find_value_two_up(i, omega1_set_up))\n",
    "    df['pred_omega1'] = new_preds_omega1\n",
    "\n",
    "    for i in df[\"pred_omega2\"]:\n",
    "        new_preds_omega2.append(find_value_two_up(i, omega2_set_up))\n",
    "    df['pred_omega2'] = new_preds_omega2\n",
    "\n",
    "    for i in df[\"pred_t1_t2\"]:\n",
    "        new_preds_t1_t2.append(find_value_two_up(i, t1_t2_set_up))\n",
    "    df['pred_t1_t2'] = new_preds_t1_t2\n",
    "\n",
    "    df.to_csv(f'Detached_sensitivity_analysis/shift_2_up/{name_of_df}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 14\n",
    "# Vytvorenie upravenych predikcii\n",
    "make_prediction_two_up(data_Bessel_U, \"pred_2_up_det_data_Bessell_U\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_Bessell_B, \"pred_2_up_det_data_Bessell_B\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_Bessell_V, \"pred_2_up_det_data_Bessell_V\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_Bessell_R, \"pred_2_up_det_data_Bessell_R\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_Bessell_I, \"pred_2_up_det_data_Bessell_I\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_SLOAN_u, \"pred_2_up_det_data_SLOAN_u\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_SLOAN_g, \"pred_2_up_det_data_SLOAN_g\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_SLOAN_r, \"pred_2_up_det_data_SLOAN_r\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_SLOAN_i, \"pred_2_up_det_data_SLOAN_i\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_SLOAN_z, \"pred_2_up_det_data_SLOAN_z\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_Kepler, \"pred_2_up_det_data_Kepler\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_GaiaDR2, \"pred_2_up_det_data_GaiaDR2\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_tess, \"pred_2_up_det_data_TESS\", det_inc, det_q, det_omega1, det_omega2, det_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vytvorenie predikcii posunutych o 1 hodnotu nizsie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 15\n",
    "# Zadefinovanie funkcie, ktora najde prvu nizsiu hodnotu v zozname unikatnych hodnot pre kazdy parameter\n",
    "def find_value_one_down(prediction, unique_values):\n",
    "    for j in range(len(unique_values)):\n",
    "        if prediction > unique_values[j]:\n",
    "            prediction = unique_values[j]\n",
    "            break\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 16\n",
    "# funkcia pre vytvorenie dat na plotovanie zo samostatnych modelov a posun hodnot predikcii na 1. nizsiu  hodnotu zo zoznamu unikatnych hodnot\n",
    "def make_prediction_one_down(df, name_of_df, model_inc, model_q, model_omega1, model_omega2, model_temp):\n",
    "    # vytvorenie pola kriviek\n",
    "    X = []\n",
    "    for row in df[\"curve\"]:\n",
    "        X.append(row)\n",
    "    X = np.array(X)\n",
    "\n",
    "    # predikcia\n",
    "    pred_inc = model_inc.predict(X).flatten()\n",
    "    pred_q = model_q.predict(X).flatten()\n",
    "    pred_pp = model_omega1.predict(X).flatten()\n",
    "    pred_sp = model_omega2.predict(X).flatten()\n",
    "    pred_tr = model_temp.predict(X).flatten()\n",
    "\n",
    "    df['pred_inc']=pred_inc\n",
    "    df['pred_q']=pred_q\n",
    "    df['pred_omega1']=pred_pp\n",
    "    df['pred_omega2']=pred_sp\n",
    "    df['pred_t1_t2']=pred_tr\n",
    "\n",
    "    new_preds_inc, new_preds_q, new_preds_omega1, new_preds_omega2, new_preds_t1_t2 = [], [], [], [], []\n",
    "\n",
    "    for i in df[\"pred_inc\"]:\n",
    "        new_preds_inc.append(find_value_one_down(i, inc_set_down))\n",
    "    df['pred_inc'] = new_preds_inc\n",
    "\n",
    "    for i in df[\"pred_q\"]:\n",
    "        new_preds_q.append(find_value_one_down(i, q_set_down))\n",
    "    df['pred_q'] = new_preds_q\n",
    "\n",
    "    for i in df[\"pred_omega1\"]:\n",
    "        new_preds_omega1.append(find_value_one_down(i, omega1_set_down))\n",
    "    df['pred_omega1'] = new_preds_omega1\n",
    "\n",
    "    for i in df[\"pred_omega2\"]:\n",
    "        new_preds_omega2.append(find_value_one_down(i, omega2_set_down))\n",
    "    df['pred_omega2'] = new_preds_omega2\n",
    "\n",
    "    for i in df[\"pred_t1_t2\"]:\n",
    "        new_preds_t1_t2.append(find_value_one_down(i, t1_t2_set_down))\n",
    "    df['pred_t1_t2'] = new_preds_t1_t2\n",
    "\n",
    "    df.to_csv(f'Detached_sensitivity_analysis/shift_1_down/{name_of_df}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blok 17\n",
    "# Vytvorenie upravenych predikcii\n",
    "make_prediction_one_down(data_Bessel_U, \"pred_1_down_det_data_Bessell_U\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_Bessell_B, \"pred_1_down_det_data_Bessell_B\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_Bessell_V, \"pred_1_down_det_data_Bessell_V\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_Bessell_R, \"pred_1_down_det_data_Bessell_R\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_Bessell_I, \"pred_1_down_det_data_Bessell_I\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_SLOAN_u, \"pred_1_down_det_data_SLOAN_u\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_SLOAN_g, \"pred_1_down_det_data_SLOAN_g\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_SLOAN_r, \"pred_1_down_det_data_SLOAN_r\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_SLOAN_i, \"pred_1_down_det_data_SLOAN_i\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_SLOAN_z, \"pred_1_down_det_data_SLOAN_z\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_Kepler, \"pred_1_down_det_data_Kepler\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_GaiaDR2, \"pred_1_down_det_data_GaiaDR2\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_tess, \"pred_1_down_det_data_TESS\", det_inc, det_q, det_omega1, det_omega2, det_temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8fc6ce4f931e35f5dd2ff00f5d2ede33ff85432a244cf6e3e9d498f6426f487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
