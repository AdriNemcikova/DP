{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity analysis\n",
    "In this Jupyter Notebook we work on sensitivity analysis of predictions of physical parameters of detached binary stars. We use predictions of 5 individual models, then we shift them 1 value up, 2 values up and 1 value down.\n",
    "Content:\n",
    "* Evironment set up\n",
    "* Data preparation\n",
    "* Shifting 1 value up\n",
    "* Shifting 2 values up\n",
    "* Shifting 1 value down"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Environment set-up\n",
    "* Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import load_model\n",
    "from ast import literal_eval\n",
    "\n",
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading individual models for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_inc = load_model(\"models/detached_inclination.hdf5\")        # inclination\n",
    "det_q = load_model(\"models/detached_mass_ratio.hdf5\")           # mass ratio\n",
    "det_omega1 = load_model(\"models/detached_pSP.hdf5\")             # primary surface potential\n",
    "det_omega2 = load_model(\"models/detached_sSP.hdf5\")             # secondary surface potential\n",
    "det_temp = load_model(\"models/detached_t1_t2.hdf5\")             # temperature ratio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining function to create file of predictions. File contains true and predicted values. Inputs:\n",
    "    * df - dataframe with id, light curve vector, name of filter and true values of physical parameters.\n",
    "    * name_of_df - name of file we want to create\n",
    "    * model_inc - model predicting inclination\n",
    "    * model_q - model predicting mass ratio\n",
    "    * model_omega1 - model predicting primary potential\n",
    "    * model_omega2 - model predicting secondary potential\n",
    "    * model_temp - model predicting temperature ratio\n",
    " * Output - file of predictions - is saved in specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_original(df, name_of_df, model_inc, model_q, model_omega1, model_omega2, model_temp):\n",
    "    # vytvorenie pola kriviek\n",
    "    X = []\n",
    "    for row in df[\"curve\"]:\n",
    "        X.append(row)\n",
    "    X = np.array(X)\n",
    "\n",
    "    # predikcia\n",
    "    pred_inc = model_inc.predict(X).flatten()\n",
    "    pred_q = model_q.predict(X).flatten()\n",
    "    pred_pp = model_omega1.predict(X).flatten()\n",
    "    pred_sp = model_omega2.predict(X).flatten()\n",
    "    pred_tr = model_temp.predict(X).flatten()\n",
    "\n",
    "    # vytvorenie vysledneho df predikcii\n",
    "    df['pred_inc']=pred_inc\n",
    "    df['pred_q']=pred_q\n",
    "    df['pred_omega1']=pred_pp\n",
    "    df['pred_omega2']=pred_sp\n",
    "    df['pred_t1_t2']=pred_tr\n",
    "\n",
    "    df.to_csv(f'Detached_sensitivity_analysis/true/{name_of_df}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data preparation\n",
    "* Synthetic detached data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>curve</th>\n",
       "      <th>primary__t_eff</th>\n",
       "      <th>secondary__t_eff</th>\n",
       "      <th>inclination</th>\n",
       "      <th>mass_ratio</th>\n",
       "      <th>primary__surface_potential</th>\n",
       "      <th>secondary__surface_potential</th>\n",
       "      <th>t1_t2</th>\n",
       "      <th>filter</th>\n",
       "      <th>critical_surface_potential</th>\n",
       "      <th>primary__equivalent_radius</th>\n",
       "      <th>secondary__equivalent_radius</th>\n",
       "      <th>primary__filling_factor</th>\n",
       "      <th>secondary__filling_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6055271686415179, 0.9842041250556204, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_U</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.608985656265516, 0.9846965713304289, 0.9998...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_B</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6189025614226916, 0.9837351924934223, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_V</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6292771409565273, 0.9832675811171884, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_R</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6543378609145588, 0.9835188424579704, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_I</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id                                              curve  \\\n",
       "0      0  38  [0.6055271686415179, 0.9842041250556204, 0.999...   \n",
       "1      1  38  [0.608985656265516, 0.9846965713304289, 0.9998...   \n",
       "2      2  38  [0.6189025614226916, 0.9837351924934223, 0.999...   \n",
       "3      3  38  [0.6292771409565273, 0.9832675811171884, 0.999...   \n",
       "4      4  38  [0.6543378609145588, 0.9835188424579704, 0.999...   \n",
       "\n",
       "   primary__t_eff  secondary__t_eff  inclination  mass_ratio  \\\n",
       "0            7000              4000     1.560796        10.0   \n",
       "1            7000              4000     1.560796        10.0   \n",
       "2            7000              4000     1.560796        10.0   \n",
       "3            7000              4000     1.560796        10.0   \n",
       "4            7000              4000     1.560796        10.0   \n",
       "\n",
       "   primary__surface_potential  secondary__surface_potential  t1_t2     filter  \\\n",
       "0                   110.00005                      996.5005   1.75  Bessell_U   \n",
       "1                   110.00005                      996.5005   1.75  Bessell_B   \n",
       "2                   110.00005                      996.5005   1.75  Bessell_V   \n",
       "3                   110.00005                      996.5005   1.75  Bessell_R   \n",
       "4                   110.00005                      996.5005   1.75  Bessell_I   \n",
       "\n",
       "   critical_surface_potential  primary__equivalent_radius  \\\n",
       "0                    15.09104                    0.009996   \n",
       "1                    15.09104                    0.009996   \n",
       "2                    15.09104                    0.009996   \n",
       "3                    15.09104                    0.009996   \n",
       "4                    15.09104                    0.009996   \n",
       "\n",
       "   secondary__equivalent_radius  primary__filling_factor  \\\n",
       "0                      0.009996              -145.333979   \n",
       "1                      0.009996              -145.333979   \n",
       "2                      0.009996              -145.333979   \n",
       "3                      0.009996              -145.333979   \n",
       "4                      0.009996              -145.333979   \n",
       "\n",
       "   secondary__filling_factor  \n",
       "0               -1502.830354  \n",
       "1               -1502.830354  \n",
       "2               -1502.830354  \n",
       "3               -1502.830354  \n",
       "4               -1502.830354  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"detached_all_parameters.pkl\").reset_index()\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **For shifting values up** we need to get list of unique values from original synthetic data for each attribute, sort them in **ascending** order and save them in specific lists\n",
    "    * inc_set_up - list of unique values for inclination\n",
    "    * q_set_up - list of unique values for mass ratio\n",
    "    * omega1_set_up - list of unique values for primary potential\n",
    "    * omega2_set_up - list of unique values for secondary potential\n",
    "    * t1_t2_set_up - list of unique values for temperature ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_set_up, q_set_up, omega1_set_up, omega2_set_up, t1_t2_set_up = [], [], [], [], []\n",
    "\n",
    "for col in data:\n",
    "    if col == \"inclination\":\n",
    "        inc_set_up = sorted(list(set(data[col])))\n",
    "    if col == \"mass_ratio\":\n",
    "        q_set_up = sorted(list(set(data[col])))\n",
    "    if col == \"primary__surface_potential\":\n",
    "        omega1_set_up = sorted(list(set(data[col])))\n",
    "    if col == \"secondary__surface_potential\":\n",
    "        omega2_set_up = sorted(list(set(data[col])))\n",
    "    if col == \"t1_t2\":\n",
    "        t1_t2_set_up = sorted(list(set(data[col])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **For shifting values down** we need to get list of unique values from original synthetic data for each attribute, sort them in **descending** order and save them in specific lists\n",
    "    * inc_set_down - list of unique values for inclination\n",
    "    * q_set_down - list of unique values for mass ratio\n",
    "    * omega1_set_down - list of unique values for primary potential\n",
    "    * omega2_set_down - list of unique values for secondary potential\n",
    "    * t1_t2_set_down - list of unique values for temperature ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_set_down, q_set_down, omega1_set_down, omega2_set_down, t1_t2_set_down = [], [], [], [], []\n",
    "\n",
    "for col in data:\n",
    "    if col == \"inclination\":\n",
    "        inc_set_down = sorted(list(set(data[col])), reverse=True)\n",
    "    if col == \"mass_ratio\":\n",
    "        q_set_down = sorted(list(set(data[col])), reverse=True)\n",
    "    if col == \"primary__surface_potential\":\n",
    "        omega1_set_down = sorted(list(set(data[col])), reverse=True)\n",
    "    if col == \"secondary__surface_potential\":\n",
    "        omega2_set_down = sorted(list(set(data[col])), reverse=True)\n",
    "    if col == \"t1_t2\":\n",
    "        t1_t2_set_down = sorted(list(set(data[col])), reverse=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create file of size random 100 records for each filter. Every dataframe created will containt id, light curve vector, name of filter and true vlaues of 5 physical parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_predict = data[[\"id\", \"curve\", \"filter\", \"inclination\", \"mass_ratio\", \"primary__surface_potential\", \"secondary__surface_potential\", \"t1_t2\"]]\n",
    "data_Bessel_U = data_to_predict[data_to_predict[\"filter\"] == \"Bessell_U\"].sample(100)\n",
    "data_Bessell_B = data_to_predict[data_to_predict[\"filter\"] == \"Bessell_B\"].sample(100)\n",
    "data_Bessell_V = data_to_predict[data_to_predict[\"filter\"] == \"Bessell_V\"].sample(100)\n",
    "data_Bessell_R = data_to_predict[data_to_predict[\"filter\"] == \"Bessell_R\"].sample(100)\n",
    "data_Bessell_I = data_to_predict[data_to_predict[\"filter\"] == \"Bessell_I\"].sample(100)\n",
    "data_SLOAN_u = data_to_predict[data_to_predict[\"filter\"] == \"SLOAN_u\"].sample(100)\n",
    "data_SLOAN_g = data_to_predict[data_to_predict[\"filter\"] == \"SLOAN_g\"].sample(100)\n",
    "data_SLOAN_r = data_to_predict[data_to_predict[\"filter\"] == \"SLOAN_r\"].sample(100)\n",
    "data_SLOAN_i = data_to_predict[data_to_predict[\"filter\"] == \"SLOAN_i\"].sample(100)\n",
    "data_SLOAN_z = data_to_predict[data_to_predict[\"filter\"] == \"SLOAN_z\"].sample(100)\n",
    "data_Kepler = data_to_predict[data_to_predict[\"filter\"] == \"Kepler\"].sample(100)\n",
    "data_GaiaDR2 = data_to_predict[data_to_predict[\"filter\"] == \"GaiaDR2\"].sample(100)\n",
    "data_tess = data_to_predict[data_to_predict[\"filter\"] == \"TESS\"].sample(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We use *make_prediction_original* function to create .csv files of true and predicted values, which we will use later for shifting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction_original(data_Bessel_U, \"orig_det_data_Bessell_U\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_Bessell_B, \"orig_det_data_Bessell_B\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_Bessell_V, \"orig_det_data_Bessell_V\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_Bessell_R, \"orig_det_data_Bessell_R\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_Bessell_I, \"orig_det_data_Bessell_I\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_SLOAN_u, \"orig_det_data_SLOAN_u\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_SLOAN_g, \"orig_det_data_SLOAN_g\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_SLOAN_r, \"orig_det_data_SLOAN_r\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_SLOAN_i, \"orig_det_data_SLOAN_i\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_SLOAN_z, \"orig_det_data_SLOAN_z\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_Kepler, \"orig_det_data_Kepler\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_GaiaDR2, \"orig_det_data_GaiaDR2\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_original(data_tess, \"orig_det_data_TESS\", det_inc, det_q, det_omega1, det_omega2, det_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Shifting predictions 1 value up\n",
    "* Defining function which will find next bigger value in the list of unique values. \n",
    "* Inputs:\n",
    "    * prediction - prediction value\n",
    "    * unique_value - list of unique values\n",
    "* Output - shifted prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_one_up(prediction, unique_values):\n",
    "    for j in range(len(unique_values)):\n",
    "        if unique_values[j] > prediction:\n",
    "            prediction = unique_values[j]\n",
    "            break\n",
    "    return prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining function which will use dataframe with true values, predict values of physical parameters and shift them 1 value up.\n",
    "* Input:\n",
    "    * df - dataframe with id, light curve vector, name of filter and true values of physical parameters\n",
    "    * name_of_df - name of file we want to create\n",
    "    * model_inc - model predicting inclination\n",
    "    * model_q - model predicting mass ratio\n",
    "    * model_omega1 - model predicting primary potential\n",
    "    * model_omega2 - model predicting secondary potential\n",
    "    * model_temp - model predicting temperature ratio\n",
    " * Output - file of shifted predictions - is saved in specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_one_up(df, name_of_df,  model_inc, model_q, model_omega1, model_omega2, model_temp):\n",
    "    X = []\n",
    "    for row in df[\"curve\"]:\n",
    "        X.append(row)\n",
    "    X = np.array(X)\n",
    "\n",
    "    pred_inc = model_inc.predict(X).flatten()\n",
    "    pred_q = model_q.predict(X).flatten()\n",
    "    pred_pp = model_omega1.predict(X).flatten()\n",
    "    pred_sp = model_omega2.predict(X).flatten()\n",
    "    pred_tr = model_temp.predict(X).flatten()\n",
    "\n",
    "    df['pred_inc']=pred_inc\n",
    "    df['pred_q']=pred_q\n",
    "    df['pred_omega1']=pred_pp\n",
    "    df['pred_omega2']=pred_sp\n",
    "    df['pred_t1_t2']=pred_tr\n",
    "\n",
    "    new_preds_inc, new_preds_q, new_preds_omega1, new_preds_omega2, new_preds_t1_t2 = [], [], [], [], []\n",
    "\n",
    "    for i in df[\"pred_inc\"]:\n",
    "        new_preds_inc.append(find_value_one_up(i, inc_set_up))\n",
    "    df['pred_inc'] = new_preds_inc\n",
    "\n",
    "    for i in df[\"pred_q\"]:\n",
    "        new_preds_q.append(find_value_one_up(i, q_set_up))\n",
    "    df['pred_q'] = new_preds_q\n",
    "\n",
    "    for i in df[\"pred_omega1\"]:\n",
    "        new_preds_omega1.append(find_value_one_up(i, omega1_set_up))\n",
    "    df['pred_omega1'] = new_preds_omega1\n",
    "\n",
    "    for i in df[\"pred_omega2\"]:\n",
    "        new_preds_omega2.append(find_value_one_up(i, omega2_set_up))\n",
    "    df['pred_omega2'] = new_preds_omega2\n",
    "\n",
    "    for i in df[\"pred_t1_t2\"]:\n",
    "        new_preds_t1_t2.append(find_value_one_up(i, t1_t2_set_up))\n",
    "    df['pred_t1_t2'] = new_preds_t1_t2\n",
    "\n",
    "    df.to_csv(f'Detached_sensitivity_analysis/shift_1_up/{name_of_df}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use of defined function to create shifted predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction_one_up(data_Bessel_U, \"pred_1_up_det_data_Bessell_U\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_Bessell_B, \"pred_1_up_det_data_Bessell_B\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_Bessell_V, \"pred_1_up_det_data_Bessell_V\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_Bessell_R, \"pred_1_up_det_data_Bessell_R\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_Bessell_I, \"pred_1_up_det_data_Bessell_I\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_SLOAN_u, \"pred_1_up_det_data_SLOAN_u\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_SLOAN_g, \"pred_1_up_det_data_SLOAN_g\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_SLOAN_r, \"pred_1_up_det_data_SLOAN_r\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_SLOAN_i, \"pred_1_up_det_data_SLOAN_i\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_SLOAN_z, \"pred_1_up_det_data_SLOAN_z\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_Kepler, \"pred_1_up_det_data_Kepler\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_GaiaDR2, \"pred_1_up_det_data_GaiaDR2\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_up(data_tess, \"pred_1_up_det_data_TESS\", det_inc, det_q, det_omega1, det_omega2, det_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Shifting predictions 2 values up\n",
    "* Defining function which will find second bigger value in the list of unique values.\n",
    "* Inputs:\n",
    "    * prediction - prediction value\n",
    "    * unique_value - list of unique values\n",
    "* Output - shifted prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_two_up(prediction, unique_values):\n",
    "    for j in range(len(unique_values)):\n",
    "        if prediction < unique_values[j] and j+1 > len(unique_values)-1:\n",
    "            prediction = max(unique_values)\n",
    "            break\n",
    "        elif prediction < unique_values[j]:\n",
    "            prediction = unique_values[j+1]\n",
    "            break\n",
    "    return prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining function which will use dataframe with true values, predict values of physical parameters and shift them 2 values up.\n",
    "* Input:\n",
    "    * df - dataframe with id, light curve vector, name of filter and true values of physical parameters\n",
    "    * name_of_df - name of file we want to create\n",
    "    * model_inc - model predicting inclination\n",
    "    * model_q - model predicting mass ratio\n",
    "    * model_omega1 - model predicting primary potential\n",
    "    * model_omega2 - model predicting secondary potential\n",
    "    * model_temp - model predicting temperature ratio\n",
    " * Output - file of shifted predictions - is saved in specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_two_up(df, name_of_df, model_inc, model_q, model_omega1, model_omega2, model_temp):\n",
    "    X = []\n",
    "    for row in df[\"curve\"]:\n",
    "        X.append(row)\n",
    "    X = np.array(X)\n",
    "\n",
    "    pred_inc = model_inc.predict(X).flatten()\n",
    "    pred_q = model_q.predict(X).flatten()\n",
    "    pred_pp = model_omega1.predict(X).flatten()\n",
    "    pred_sp = model_omega2.predict(X).flatten()\n",
    "    pred_tr = model_temp.predict(X).flatten()\n",
    "\n",
    "    df['pred_inc']=pred_inc\n",
    "    df['pred_q']=pred_q\n",
    "    df['pred_omega1']=pred_pp\n",
    "    df['pred_omega2']=pred_sp\n",
    "    df['pred_t1_t2']=pred_tr\n",
    "\n",
    "    new_preds_inc, new_preds_q, new_preds_omega1, new_preds_omega2, new_preds_t1_t2 = [], [], [], [], []\n",
    "\n",
    "    for i in df[\"pred_inc\"]:\n",
    "        new_preds_inc.append(find_value_two_up(i, inc_set_up))\n",
    "    df['pred_inc'] = new_preds_inc\n",
    "\n",
    "    for i in df[\"pred_q\"]:\n",
    "        new_preds_q.append(find_value_two_up(i, q_set_up))\n",
    "    df['pred_q'] = new_preds_q\n",
    "\n",
    "    for i in df[\"pred_omega1\"]:\n",
    "        new_preds_omega1.append(find_value_two_up(i, omega1_set_up))\n",
    "    df['pred_omega1'] = new_preds_omega1\n",
    "\n",
    "    for i in df[\"pred_omega2\"]:\n",
    "        new_preds_omega2.append(find_value_two_up(i, omega2_set_up))\n",
    "    df['pred_omega2'] = new_preds_omega2\n",
    "\n",
    "    for i in df[\"pred_t1_t2\"]:\n",
    "        new_preds_t1_t2.append(find_value_two_up(i, t1_t2_set_up))\n",
    "    df['pred_t1_t2'] = new_preds_t1_t2\n",
    "\n",
    "    df.to_csv(f'Detached_sensitivity_analysis/shift_2_up/{name_of_df}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use of defined function to create shifted predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction_two_up(data_Bessel_U, \"pred_2_up_det_data_Bessell_U\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_Bessell_B, \"pred_2_up_det_data_Bessell_B\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_Bessell_V, \"pred_2_up_det_data_Bessell_V\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_Bessell_R, \"pred_2_up_det_data_Bessell_R\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_Bessell_I, \"pred_2_up_det_data_Bessell_I\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_SLOAN_u, \"pred_2_up_det_data_SLOAN_u\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_SLOAN_g, \"pred_2_up_det_data_SLOAN_g\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_SLOAN_r, \"pred_2_up_det_data_SLOAN_r\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_SLOAN_i, \"pred_2_up_det_data_SLOAN_i\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_SLOAN_z, \"pred_2_up_det_data_SLOAN_z\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_Kepler, \"pred_2_up_det_data_Kepler\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_GaiaDR2, \"pred_2_up_det_data_GaiaDR2\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_two_up(data_tess, \"pred_2_up_det_data_TESS\", det_inc, det_q, det_omega1, det_omega2, det_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Shifting predictions 1 value down\n",
    "* Defining function which will find first smaller value in the list of unique values.\n",
    "* Inputs:\n",
    "    * prediction - prediction value\n",
    "    * unique_value - list of unique values\n",
    "* Output - shifted prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_value_one_down(prediction, unique_values):\n",
    "    for j in range(len(unique_values)):\n",
    "        if prediction > unique_values[j]:\n",
    "            prediction = unique_values[j]\n",
    "            break\n",
    "    return prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining function which will use dataframe with true values, predict values of physical parameters and shift them 1 value down.\n",
    "* Input:\n",
    "    * df - dataframe with id, light curve vector, name of filter and true values of physical parameters\n",
    "    * name_of_df - name of file we want to create\n",
    "    * model_inc - model predicting inclination\n",
    "    * model_q - model predicting mass ratio\n",
    "    * model_omega1 - model predicting primary potential\n",
    "    * model_omega2 - model predicting secondary potential\n",
    "    * model_temp - model predicting temperature ratio\n",
    " * Output - file of shifted predictions - is saved in specific folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction_one_down(df, name_of_df, model_inc, model_q, model_omega1, model_omega2, model_temp):\n",
    "    X = []\n",
    "    for row in df[\"curve\"]:\n",
    "        X.append(row)\n",
    "    X = np.array(X)\n",
    "\n",
    "    pred_inc = model_inc.predict(X).flatten()\n",
    "    pred_q = model_q.predict(X).flatten()\n",
    "    pred_pp = model_omega1.predict(X).flatten()\n",
    "    pred_sp = model_omega2.predict(X).flatten()\n",
    "    pred_tr = model_temp.predict(X).flatten()\n",
    "\n",
    "    df['pred_inc']=pred_inc\n",
    "    df['pred_q']=pred_q\n",
    "    df['pred_omega1']=pred_pp\n",
    "    df['pred_omega2']=pred_sp\n",
    "    df['pred_t1_t2']=pred_tr\n",
    "\n",
    "    new_preds_inc, new_preds_q, new_preds_omega1, new_preds_omega2, new_preds_t1_t2 = [], [], [], [], []\n",
    "\n",
    "    for i in df[\"pred_inc\"]:\n",
    "        new_preds_inc.append(find_value_one_down(i, inc_set_down))\n",
    "    df['pred_inc'] = new_preds_inc\n",
    "\n",
    "    for i in df[\"pred_q\"]:\n",
    "        new_preds_q.append(find_value_one_down(i, q_set_down))\n",
    "    df['pred_q'] = new_preds_q\n",
    "\n",
    "    for i in df[\"pred_omega1\"]:\n",
    "        new_preds_omega1.append(find_value_one_down(i, omega1_set_down))\n",
    "    df['pred_omega1'] = new_preds_omega1\n",
    "\n",
    "    for i in df[\"pred_omega2\"]:\n",
    "        new_preds_omega2.append(find_value_one_down(i, omega2_set_down))\n",
    "    df['pred_omega2'] = new_preds_omega2\n",
    "\n",
    "    for i in df[\"pred_t1_t2\"]:\n",
    "        new_preds_t1_t2.append(find_value_one_down(i, t1_t2_set_down))\n",
    "    df['pred_t1_t2'] = new_preds_t1_t2\n",
    "\n",
    "    df.to_csv(f'Detached_sensitivity_analysis/shift_1_down/{name_of_df}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use of defined function to create shifted predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction_one_down(data_Bessel_U, \"pred_1_down_det_data_Bessell_U\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_Bessell_B, \"pred_1_down_det_data_Bessell_B\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_Bessell_V, \"pred_1_down_det_data_Bessell_V\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_Bessell_R, \"pred_1_down_det_data_Bessell_R\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_Bessell_I, \"pred_1_down_det_data_Bessell_I\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_SLOAN_u, \"pred_1_down_det_data_SLOAN_u\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_SLOAN_g, \"pred_1_down_det_data_SLOAN_g\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_SLOAN_r, \"pred_1_down_det_data_SLOAN_r\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_SLOAN_i, \"pred_1_down_det_data_SLOAN_i\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_SLOAN_z, \"pred_1_down_det_data_SLOAN_z\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_Kepler, \"pred_1_down_det_data_Kepler\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_GaiaDR2, \"pred_1_down_det_data_GaiaDR2\", det_inc, det_q, det_omega1, det_omega2, det_temp)\n",
    "make_prediction_one_down(data_tess, \"pred_1_down_det_data_TESS\", det_inc, det_q, det_omega1, det_omega2, det_temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8fc6ce4f931e35f5dd2ff00f5d2ede33ff85432a244cf6e3e9d498f6426f487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
