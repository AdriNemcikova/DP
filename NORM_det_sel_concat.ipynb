{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predikcia detached kriviek vybranych parametrov\n",
    "### Model NN s concatenate vrstvou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Dense, concatenate, Activation, LSTM, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import Concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_observation_sigma(space_obs_frac=0.5):\n",
    "    \"\"\"\n",
    "    Draws a standard deviation of noise in light curve points from a \"true\" value provided in synthetic light curve.\n",
    "    Noise sigma is drawn from bimodal distribution taking into account contributions from space based and earth based\n",
    "    observations which have different levels of stochastic noise.\n",
    "\n",
    "    :param space_obs_frac: ratio between earth based and space based observations\n",
    "    :return: float; standard deviation of the light curve noise\n",
    "    \"\"\"\n",
    "    earth_based_sigma = 4e-3\n",
    "    space_based_sigma = 2e-4\n",
    "    sigma = np.random.choice([earth_based_sigma, space_based_sigma], p=[1-space_obs_frac, space_obs_frac])\n",
    "    return np.random.rayleigh(sigma)\n",
    "\n",
    "def stochastic_noise_generator(curve):\n",
    "    \"\"\"\n",
    "    Introduces gaussian noise into synthetic observation provided in `curve`.\n",
    "\n",
    "    :param curve: numpy.array; normalized light curve\n",
    "    :return: Tuple(numpy.array, float); normalized light curve with added noise, standard deviation of observations\n",
    "    \"\"\"\n",
    "    sigma = generate_observation_sigma()\n",
    "    return np.random.normal(curve, sigma), np.full(curve.shape, sigma)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"detached_all_parameters.pkl\").reset_index()\n",
    "data_sample = data.sample(n=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for row in data_sample[\"curve\"]:\n",
    "    X.append(row)\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data_sample[[\n",
    "    \"inclination\",\n",
    "    \"mass_ratio\",\n",
    "    \"primary__surface_potential\",\n",
    "    \"secondary__surface_potential\",\n",
    "    \"t1_t2\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71584635, 0.05050505, 0.17208073, 0.0020424 , 0.7804878 ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMax Scaler\n",
    "scaler = MinMaxScaler()\n",
    "y_minmax_scaled = scaler.fit_transform(y)\n",
    "y_minmax_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y_minmax_scaled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to train data\n",
    "X_train_n = []\n",
    "y_train_n = []\n",
    "for i in range(len(X_train1)):\n",
    "    for j in range(3):\n",
    "        curve = stochastic_noise_generator(X_train1[i])\n",
    "        X_train_n.append(curve[0])\n",
    "        y_train_n.append(y_train1[i])\n",
    "X_train_n = np.array(X_train_n)\n",
    "y_train_n=np.array(y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in dataset:  1300000 \n",
      "Number of records in sample:  200000 \n",
      "Number of train data without noise:  160000 \n",
      "Number of train data with noise:  480000 \n",
      "Number of test data without noise:  40000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in dataset: \", len(data),\n",
    "    \"\\nNumber of records in sample: \", len(X),\n",
    "    \"\\nNumber of train data without noise: \", len(X_train1),\n",
    "    \"\\nNumber of train data with noise: \", len(X_train_n),\n",
    "    \"\\nNumber of test data without noise: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480000, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_inc = np.array([arr[0] for arr in y_train_n])\n",
    "y_mass = np.array([arr[1] for arr in y_train_n])\n",
    "y_prim_potent = np.array([arr[2] for arr in y_train_n])\n",
    "y_sec_potent = np.array([arr[3] for arr in y_train_n])\n",
    "y_temp_ratio = np.array([arr[4] for arr in y_train_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_inc.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_47\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 400, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 398, 64)      256         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 398, 64)      256         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 398, 64)      256         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 398, 64)      256         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 398, 64)      256         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 199, 64)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 199, 64)      0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 199, 64)      0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 199, 64)      0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 199, 64)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 197, 32)      6176        max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 197, 32)      6176        max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 197, 32)      6176        max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 197, 32)      6176        max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 197, 32)      6176        max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 197, 32)      1056        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 197, 32)      1056        conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 197, 32)      1056        conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 197, 32)      1056        conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 197, 32)      1056        conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 197, 160)     0           dense_24[0][0]                   \n",
      "                                                                 dense_25[0][0]                   \n",
      "                                                                 dense_26[0][0]                   \n",
      "                                                                 dense_27[0][0]                   \n",
      "                                                                 dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 31520)        0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 32)           1008672     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 32)           1056        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 5)            165         dense_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,047,333\n",
      "Trainable params: 1,047,333\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs_y = Input(shape=(X_train_n.shape[1], 1))\n",
    "\n",
    "a = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs_y)\n",
    "a = MaxPooling1D(2)(a)\n",
    "a = Conv1D(32, kernel_size = 3, padding = \"valid\")(a)\n",
    "a = Dense(32, activation='relu')(a)\n",
    "a = Model(inputs=inputs_y, outputs=a)\n",
    "\n",
    "b = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs_y)\n",
    "b = MaxPooling1D(2)(b)\n",
    "b = Conv1D(32, kernel_size = 3, padding = \"valid\")(b)\n",
    "b = Dense(32, activation='relu')(b)\n",
    "b = Model(inputs=inputs_y, outputs=b)\n",
    "\n",
    "c = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs_y)\n",
    "c = MaxPooling1D(2)(c)\n",
    "c = Conv1D(32, kernel_size = 3, padding = \"valid\")(c)\n",
    "c = Dense(32, activation='relu')(c)\n",
    "c = Model(inputs=inputs_y, outputs=c)\n",
    "\n",
    "d = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs_y)\n",
    "d = MaxPooling1D(2)(d)\n",
    "d = Conv1D(32, kernel_size = 3, padding = \"valid\")(d)\n",
    "d = Dense(32, activation='relu')(d)\n",
    "d = Model(inputs=inputs_y, outputs=d)\n",
    "\n",
    "e = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs_y)\n",
    "e = MaxPooling1D(2)(e)\n",
    "e = Conv1D(32, kernel_size = 3, padding = \"valid\")(e)\n",
    "e = Dense(32, activation='relu')(e)\n",
    "e = Model(inputs=inputs_y, outputs=e)\n",
    "\n",
    "x = concatenate([a.output, b.output, c.output, d.output, e.output])\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "\n",
    "output = Dense(5, activation='linear')(x)\n",
    "\n",
    "model_multi = Model(inputs=inputs_y, outputs=output)\n",
    "model_multi.compile(loss='mse', optimizer='adam', metrics=[\"mae\", \"mape\"])\n",
    "print(model_multi.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = \"models/norm_det_multi_v1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor = 'val_mae', verbose = 1, save_best_only = True, mode = 'min')\n",
    "early = EarlyStopping(monitor = \"val_mae\", mode = \"min\", patience = 25)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 176/6750 [..............................] - ETA: 20:36 - loss: 0.0737 - mae: 0.2013 - mape: 69728.0625"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nemci\\OneDrive\\Počítač\\DP\\NORM_det_sel_concat.ipynb Cell 18\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nemci/OneDrive/Po%C4%8D%C3%ADta%C4%8D/DP/NORM_det_sel_concat.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history_multi \u001b[39m=\u001b[39m model_multi\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nemci/OneDrive/Po%C4%8D%C3%ADta%C4%8D/DP/NORM_det_sel_concat.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     x\u001b[39m=\u001b[39;49mX_train_n,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nemci/OneDrive/Po%C4%8D%C3%ADta%C4%8D/DP/NORM_det_sel_concat.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     y\u001b[39m=\u001b[39;49m[y_inc, y_mass, y_prim_potent, y_sec_potent, y_temp_ratio],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nemci/OneDrive/Po%C4%8D%C3%ADta%C4%8D/DP/NORM_det_sel_concat.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     validation_split \u001b[39m=\u001b[39;49m \u001b[39m0.1\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nemci/OneDrive/Po%C4%8D%C3%ADta%C4%8D/DP/NORM_det_sel_concat.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nemci/OneDrive/Po%C4%8D%C3%ADta%C4%8D/DP/NORM_det_sel_concat.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nemci/OneDrive/Po%C4%8D%C3%ADta%C4%8D/DP/NORM_det_sel_concat.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     callbacks \u001b[39m=\u001b[39;49m callbacks_list,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nemci/OneDrive/Po%C4%8D%C3%ADta%C4%8D/DP/NORM_det_sel_concat.ipynb#X23sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     batch_size \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\nemci\\anaconda3\\envs\\global\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_method_wrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_multi_worker_mode():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    110\u001b[0m   \u001b[39m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[39mif\u001b[39;00m dc_context\u001b[39m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32mc:\\Users\\nemci\\anaconda3\\envs\\global\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1098\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1092\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTraceContext\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1093\u001b[0m     graph_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1094\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1095\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1096\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size):\n\u001b[0;32m   1097\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1098\u001b[0m   tmp_logs \u001b[39m=\u001b[39m train_function(iterator)\n\u001b[0;32m   1099\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1100\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\nemci\\anaconda3\\envs\\global\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m   compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 780\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    782\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    783\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\nemci\\anaconda3\\envs\\global\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:807\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    804\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    805\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    806\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    809\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    810\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\nemci\\anaconda3\\envs\\global\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2829\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2828\u001b[0m   graph_function, args, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2829\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_filtered_call(args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\nemci\\anaconda3\\envs\\global\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1843\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_filtered_call\u001b[39m(\u001b[39mself\u001b[39m, args, kwargs, cancellation_manager\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1828\u001b[0m   \u001b[39m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m \n\u001b[0;32m   1830\u001b[0m \u001b[39m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[39m    `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m   1842\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1843\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   1844\u001b[0m       [t \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m nest\u001b[39m.\u001b[39;49mflatten((args, kwargs), expand_composites\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1845\u001b[0m        \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(t, (ops\u001b[39m.\u001b[39;49mTensor,\n\u001b[0;32m   1846\u001b[0m                          resource_variable_ops\u001b[39m.\u001b[39;49mBaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m       captured_inputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcaptured_inputs,\n\u001b[0;32m   1848\u001b[0m       cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\nemci\\anaconda3\\envs\\global\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1923\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1918\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m (\n\u001b[0;32m   1919\u001b[0m     pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0;32m   1920\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1921\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1922\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1923\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1924\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1925\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m     args,\n\u001b[0;32m   1927\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1928\u001b[0m     executing_eagerly)\n\u001b[0;32m   1929\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\nemci\\anaconda3\\envs\\global\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:545\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    544\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 545\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    546\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    547\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    548\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    549\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    550\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    551\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    553\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    554\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    558\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\nemci\\anaconda3\\envs\\global\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_multi = model_multi.fit(\n",
    "    x=X_train_n,\n",
    "    y=[y_inc, y_mass, y_prim_potent, y_sec_potent, y_temp_ratio],\n",
    "    validation_split = 0.1,\n",
    "    epochs = 10,\n",
    "    verbose = 1,\n",
    "    callbacks = callbacks_list,\n",
    "    batch_size = 64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "global",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8fc6ce4f931e35f5dd2ff00f5d2ede33ff85432a244cf6e3e9d498f6426f487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
