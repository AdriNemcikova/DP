{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predikcia vsetkych parametrov pomocou jednej NN\n",
    "## Normovane detached data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Dense, concatenate, Activation, LSTM, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import Concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_observation_sigma(space_obs_frac=0.5):\n",
    "    \"\"\"\n",
    "    Draws a standard deviation of noise in light curve points from a \"true\" value provided in synthetic light curve.\n",
    "    Noise sigma is drawn from bimodal distribution taking into account contributions from space based and earth based\n",
    "    observations which have different levels of stochastic noise.\n",
    "\n",
    "    :param space_obs_frac: ratio between earth based and space based observations\n",
    "    :return: float; standard deviation of the light curve noise\n",
    "    \"\"\"\n",
    "    earth_based_sigma = 4e-3\n",
    "    space_based_sigma = 2e-4\n",
    "    sigma = np.random.choice([earth_based_sigma, space_based_sigma], p=[1-space_obs_frac, space_obs_frac])\n",
    "    return np.random.rayleigh(sigma)\n",
    "\n",
    "def stochastic_noise_generator(curve):\n",
    "    \"\"\"\n",
    "    Introduces gaussian noise into synthetic observation provided in `curve`.\n",
    "\n",
    "    :param curve: numpy.array; normalized light curve\n",
    "    :return: Tuple(numpy.array, float); normalized light curve with added noise, standard deviation of observations\n",
    "    \"\"\"\n",
    "    sigma = generate_observation_sigma()\n",
    "    return np.random.normal(curve, sigma), np.full(curve.shape, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"detached_all_parameters.pkl\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>curve</th>\n",
       "      <th>primary__t_eff</th>\n",
       "      <th>secondary__t_eff</th>\n",
       "      <th>inclination</th>\n",
       "      <th>mass_ratio</th>\n",
       "      <th>primary__surface_potential</th>\n",
       "      <th>secondary__surface_potential</th>\n",
       "      <th>t1_t2</th>\n",
       "      <th>filter</th>\n",
       "      <th>critical_surface_potential</th>\n",
       "      <th>primary__equivalent_radius</th>\n",
       "      <th>secondary__equivalent_radius</th>\n",
       "      <th>primary__filling_factor</th>\n",
       "      <th>secondary__filling_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6055271686415179, 0.9842041250556204, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_U</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.608985656265516, 0.9846965713304289, 0.9998...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_B</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6189025614226916, 0.9837351924934223, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_V</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6292771409565273, 0.9832675811171884, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_R</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6543378609145588, 0.9835188424579704, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_I</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id                                              curve  \\\n",
       "0      0  38  [0.6055271686415179, 0.9842041250556204, 0.999...   \n",
       "1      1  38  [0.608985656265516, 0.9846965713304289, 0.9998...   \n",
       "2      2  38  [0.6189025614226916, 0.9837351924934223, 0.999...   \n",
       "3      3  38  [0.6292771409565273, 0.9832675811171884, 0.999...   \n",
       "4      4  38  [0.6543378609145588, 0.9835188424579704, 0.999...   \n",
       "\n",
       "   primary__t_eff  secondary__t_eff  inclination  mass_ratio  \\\n",
       "0            7000              4000     1.560796        10.0   \n",
       "1            7000              4000     1.560796        10.0   \n",
       "2            7000              4000     1.560796        10.0   \n",
       "3            7000              4000     1.560796        10.0   \n",
       "4            7000              4000     1.560796        10.0   \n",
       "\n",
       "   primary__surface_potential  secondary__surface_potential  t1_t2     filter  \\\n",
       "0                   110.00005                      996.5005   1.75  Bessell_U   \n",
       "1                   110.00005                      996.5005   1.75  Bessell_B   \n",
       "2                   110.00005                      996.5005   1.75  Bessell_V   \n",
       "3                   110.00005                      996.5005   1.75  Bessell_R   \n",
       "4                   110.00005                      996.5005   1.75  Bessell_I   \n",
       "\n",
       "   critical_surface_potential  primary__equivalent_radius  \\\n",
       "0                    15.09104                    0.009996   \n",
       "1                    15.09104                    0.009996   \n",
       "2                    15.09104                    0.009996   \n",
       "3                    15.09104                    0.009996   \n",
       "4                    15.09104                    0.009996   \n",
       "\n",
       "   secondary__equivalent_radius  primary__filling_factor  \\\n",
       "0                      0.009996              -145.333979   \n",
       "1                      0.009996              -145.333979   \n",
       "2                      0.009996              -145.333979   \n",
       "3                      0.009996              -145.333979   \n",
       "4                      0.009996              -145.333979   \n",
       "\n",
       "   secondary__filling_factor  \n",
       "0               -1502.830354  \n",
       "1               -1502.830354  \n",
       "2               -1502.830354  \n",
       "3               -1502.830354  \n",
       "4               -1502.830354  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['index',\n",
       " 'id',\n",
       " 'curve',\n",
       " 'primary__t_eff',\n",
       " 'secondary__t_eff',\n",
       " 'inclination',\n",
       " 'mass_ratio',\n",
       " 'primary__surface_potential',\n",
       " 'secondary__surface_potential',\n",
       " 't1_t2',\n",
       " 'filter',\n",
       " 'critical_surface_potential',\n",
       " 'primary__equivalent_radius',\n",
       " 'secondary__equivalent_radius',\n",
       " 'primary__filling_factor',\n",
       " 'secondary__filling_factor']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_sample.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for row in data_sample[\"curve\"]:\n",
    "    X.append(row)\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data_sample[[\n",
    "    \"primary__t_eff\",\n",
    "    \"secondary__t_eff\",\n",
    "    \"inclination\",\n",
    "    \"mass_ratio\",\n",
    "    \"primary__surface_potential\",\n",
    "    \"secondary__surface_potential\",\n",
    "    \"t1_t2\",\n",
    "    \"critical_surface_potential\",\n",
    "    \"primary__equivalent_radius\",\n",
    "    \"secondary__equivalent_radius\",\n",
    "    \"primary__filling_factor\",\n",
    "    \"secondary__filling_factor\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.50000000e+04,  5.00000000e+03,  1.33407634e+00,  6.00000000e-01,\n",
       "        2.06012514e+01,  4.07107635e+00,  9.00000000e+00,  3.06344154e+00,\n",
       "        4.99813455e-02,  2.10723804e-01, -4.99552049e+01, -2.87017614e+00])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.02439024, 0.71584635, 0.05050505, 0.17208073,\n",
       "       0.0020424 , 0.7804878 , 0.08409557, 0.07311887, 0.36706089,\n",
       "       0.96675942, 0.99809033])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMax Scaler\n",
    "scaler = MinMaxScaler()\n",
    "y_minmax_scaled = scaler.fit_transform(y)\n",
    "y_minmax_scaled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y_minmax_scaled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to data\n",
    "X_train_n = []\n",
    "y_train_n = []\n",
    "for i in range(len(X_train1)):\n",
    "    for j in range(3):\n",
    "        curve = stochastic_noise_generator(X_train1[i])\n",
    "        X_train_n.append(curve[0])\n",
    "        y_train_n.append(y_train1[i])\n",
    "X_train_n = np.array(X_train_n)\n",
    "y_train_n=np.array(y_train_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in dataset:  1300000 \n",
      "Number of records in sample:  100000 \n",
      "Number of train data without noise:  80000 \n",
      "Number of train data with noise:  240000 \n",
      "Number of test data without noise:  20000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in dataset: \", len(data),\n",
    "    \"\\nNumber of records in sample: \", len(X),\n",
    "    \"\\nNumber of train data without noise: \", len(X_train1),\n",
    "    \"\\nNumber of train data with noise: \", len(X_train_n),\n",
    "    \"\\nNumber of test data without noise: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 400, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 398, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 199, 64)           33024     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12736)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                815168    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 850,924\n",
      "Trainable params: 850,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(400, 1))\n",
    "b = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs)\n",
    "b = MaxPooling1D(2)(b)\n",
    "b = Dropout(0.2)(b)\n",
    "b = LSTM(64, return_sequences=True)(b)\n",
    "b = Flatten()(b)\n",
    "b = Dense(64, activation='relu')(b)\n",
    "x = Dense(32, activation='relu')(b)\n",
    "output = Dense(12, activation='linear')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mae\", \"mape\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = \"models/norm_detached_all_params.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor = 'val_mae', verbose = 1, save_best_only = True, mode = 'min')\n",
    "early = EarlyStopping(monitor = \"val_mae\", mode = \"min\", patience = 25)\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0274 - mae: 0.1068 - mape: 5080980.5000\n",
      "Epoch 00001: val_mae improved from inf to 0.09556, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 425s 126ms/step - loss: 0.0274 - mae: 0.1068 - mape: 5080980.5000 - val_loss: 0.0222 - val_mae: 0.0956 - val_mape: 4508048.0000\n",
      "Epoch 2/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0215 - mae: 0.0917 - mape: 4007379.0000\n",
      "Epoch 00002: val_mae improved from 0.09556 to 0.08633, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 408s 121ms/step - loss: 0.0215 - mae: 0.0917 - mape: 4007379.0000 - val_loss: 0.0196 - val_mae: 0.0863 - val_mape: 4008381.7500\n",
      "Epoch 3/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0199 - mae: 0.0868 - mape: 3680181.7500\n",
      "Epoch 00003: val_mae improved from 0.08633 to 0.08368, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 411s 122ms/step - loss: 0.0199 - mae: 0.0868 - mape: 3680181.7500 - val_loss: 0.0186 - val_mae: 0.0837 - val_mape: 3420719.0000\n",
      "Epoch 4/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0188 - mae: 0.0835 - mape: 3501387.0000\n",
      "Epoch 00004: val_mae improved from 0.08368 to 0.07832, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 416s 123ms/step - loss: 0.0188 - mae: 0.0835 - mape: 3501387.0000 - val_loss: 0.0174 - val_mae: 0.0783 - val_mape: 3229455.0000\n",
      "Epoch 5/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0178 - mae: 0.0805 - mape: 3333637.5000\n",
      "Epoch 00005: val_mae improved from 0.07832 to 0.07459, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 404s 120ms/step - loss: 0.0178 - mae: 0.0805 - mape: 3333637.5000 - val_loss: 0.0162 - val_mae: 0.0746 - val_mape: 2972578.2500\n",
      "Epoch 6/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0171 - mae: 0.0779 - mape: 3216459.0000\n",
      "Epoch 00006: val_mae did not improve from 0.07459\n",
      "3375/3375 [==============================] - 408s 121ms/step - loss: 0.0171 - mae: 0.0779 - mape: 3216459.0000 - val_loss: 0.0159 - val_mae: 0.0765 - val_mape: 3444212.7500\n",
      "Epoch 7/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0164 - mae: 0.0759 - mape: 3134341.5000\n",
      "Epoch 00007: val_mae improved from 0.07459 to 0.07284, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 409s 121ms/step - loss: 0.0164 - mae: 0.0759 - mape: 3134341.5000 - val_loss: 0.0155 - val_mae: 0.0728 - val_mape: 3277366.2500\n",
      "Epoch 8/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0160 - mae: 0.0745 - mape: 3065457.7500\n",
      "Epoch 00008: val_mae improved from 0.07284 to 0.07153, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 415s 123ms/step - loss: 0.0160 - mae: 0.0745 - mape: 3065457.7500 - val_loss: 0.0151 - val_mae: 0.0715 - val_mape: 3019149.0000\n",
      "Epoch 9/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0156 - mae: 0.0731 - mape: 3005823.5000\n",
      "Epoch 00009: val_mae improved from 0.07153 to 0.06848, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 559s 166ms/step - loss: 0.0156 - mae: 0.0731 - mape: 3005823.5000 - val_loss: 0.0145 - val_mae: 0.0685 - val_mape: 2914808.2500\n",
      "Epoch 10/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0153 - mae: 0.0722 - mape: 2940504.5000 ETA: 2s - loss: 0.0153 - \n",
      "Epoch 00010: val_mae did not improve from 0.06848\n",
      "3375/3375 [==============================] - 604s 179ms/step - loss: 0.0153 - mae: 0.0722 - mape: 2940504.5000 - val_loss: 0.0145 - val_mae: 0.0695 - val_mape: 2890226.2500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_n, y_train_n, validation_split = 0.1, epochs = 10, verbose = 1, callbacks = callbacks_list, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"models/norm_detached_all_params.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation on normalized test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluated on normalized test data without noise\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding noise to normalized test data\n",
    "X_test_n = []\n",
    "y_test_norm_n = []\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(3):\n",
    "        curve = stochastic_noise_generator(X_test[i])\n",
    "        X_test_n.append(curve[0])\n",
    "        y_test_norm_n.append(y_test[i])\n",
    "        j += 1\n",
    "X_test_n = np.array(X_test_n)\n",
    "y_test_norm_n = np.array(y_test_norm_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluated on normalized test data with noise\n",
    "model.evaluate(X_test_n, y_test_norm_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on normalized test data withou noise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('global')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8fc6ce4f931e35f5dd2ff00f5d2ede33ff85432a244cf6e3e9d498f6426f487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
