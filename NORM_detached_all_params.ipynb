{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of normalized physical parameters of odetached data with simple combined NN model\n",
    "In this Jupyter Notebook we will train NN model to predict normalized physical parameter of detached binary systems. Content:\n",
    "* Libraries, functions\n",
    "* Data preparation\n",
    "* Create architecture of NN model\n",
    "* Evaluation of model\n",
    "* Predictions\n",
    "* Evaluation of predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment set-up\n",
    "* Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, MaxPooling1D, Input, Dense, LSTM, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining functions for noise generation, set-up of random sigma value generator.\n",
    "* Inputs:\n",
    "    * for function generate_observation_sigma(space_obs_frac=0.5) - space_obs_frac=0.5\n",
    "    * for function stochastic_noise_generator(curve) - vector of light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_observation_sigma(space_obs_frac=0.5):\n",
    "    \"\"\"\n",
    "    Draws a standard deviation of noise in light curve points from a \"true\" value provided in synthetic light curve.\n",
    "    Noise sigma is drawn from bimodal distribution taking into account contributions from space based and earth based\n",
    "    observations which have different levels of stochastic noise.\n",
    "\n",
    "    :param space_obs_frac: ratio between earth based and space based observations\n",
    "    :return: float; standard deviation of the light curve noise\n",
    "    \"\"\"\n",
    "    earth_based_sigma = 4e-3\n",
    "    space_based_sigma = 2e-4\n",
    "    sigma = np.random.choice([earth_based_sigma, space_based_sigma], p=[1-space_obs_frac, space_obs_frac])\n",
    "    return np.random.rayleigh(sigma)\n",
    "\n",
    "def stochastic_noise_generator(curve):\n",
    "    \"\"\"\n",
    "    Introduces gaussian noise into synthetic observation provided in `curve`.\n",
    "\n",
    "    :param curve: numpy.array; normalized light curve\n",
    "    :return: Tuple(numpy.array, float); normalized light curve with added noise, standard deviation of observations\n",
    "    \"\"\"\n",
    "    sigma = generate_observation_sigma()\n",
    "    return np.random.normal(curve, sigma), np.full(curve.shape, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data loading\n",
    "* Loading synthetic data from .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>curve</th>\n",
       "      <th>primary__t_eff</th>\n",
       "      <th>secondary__t_eff</th>\n",
       "      <th>inclination</th>\n",
       "      <th>mass_ratio</th>\n",
       "      <th>primary__surface_potential</th>\n",
       "      <th>secondary__surface_potential</th>\n",
       "      <th>t1_t2</th>\n",
       "      <th>filter</th>\n",
       "      <th>critical_surface_potential</th>\n",
       "      <th>primary__equivalent_radius</th>\n",
       "      <th>secondary__equivalent_radius</th>\n",
       "      <th>primary__filling_factor</th>\n",
       "      <th>secondary__filling_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6055271686415179, 0.9842041250556204, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_U</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.608985656265516, 0.9846965713304289, 0.9998...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_B</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6189025614226916, 0.9837351924934223, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_V</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6292771409565273, 0.9832675811171884, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_R</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>[0.6543378609145588, 0.9835188424579704, 0.999...</td>\n",
       "      <td>7000</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.560796</td>\n",
       "      <td>10.0</td>\n",
       "      <td>110.00005</td>\n",
       "      <td>996.5005</td>\n",
       "      <td>1.75</td>\n",
       "      <td>Bessell_I</td>\n",
       "      <td>15.09104</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>-145.333979</td>\n",
       "      <td>-1502.830354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id  ... primary__filling_factor  secondary__filling_factor\n",
       "0      0  38  ...             -145.333979               -1502.830354\n",
       "1      1  38  ...             -145.333979               -1502.830354\n",
       "2      2  38  ...             -145.333979               -1502.830354\n",
       "3      3  38  ...             -145.333979               -1502.830354\n",
       "4      4  38  ...             -145.333979               -1502.830354\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle(\"detached_all_parameters.pkl\").reset_index()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Selecting random sample of data of size 100 000 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create multi-dimensional array of vectors of light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for row in data_sample[\"curve\"]:\n",
    "    X.append(row)\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create array of features, which will model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data_sample[[\n",
    "    \"primary__t_eff\",\n",
    "    \"secondary__t_eff\",\n",
    "    \"inclination\",\n",
    "    \"mass_ratio\",\n",
    "    \"primary__surface_potential\",\n",
    "    \"secondary__surface_potential\",\n",
    "    \"t1_t2\",\n",
    "    \"critical_surface_potential\",\n",
    "    \"primary__equivalent_radius\",\n",
    "    \"secondary__equivalent_radius\",\n",
    "    \"primary__filling_factor\",\n",
    "    \"secondary__filling_factor\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining MinMax scaler object\n",
    "* Fitting scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.02439024, 0.71584635, 0.05050505, 0.17208073,\n",
       "       0.0020424 , 0.7804878 , 0.08409557, 0.07311887, 0.36706089,\n",
       "       0.96675942, 0.99809033])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "y_minmax_scaled = scaler.fit_transform(y)\n",
    "y_minmax_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Splitting data into training and testing data sets in 80:20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y_minmax_scaled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding noise into training datasets (noise generated with functions defined earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n = []\n",
    "y_train_n = []\n",
    "for i in range(len(X_train1)):\n",
    "    for j in range(3):\n",
    "        curve = stochastic_noise_generator(X_train1[i])\n",
    "        X_train_n.append(curve[0])\n",
    "        y_train_n.append(y_train1[i])\n",
    "X_train_n = np.array(X_train_n)\n",
    "y_train_n=np.array(y_train_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Details about number of records in specific data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in dataset:  1300000 \n",
      "Number of records in sample:  100000 \n",
      "Number of train data without noise:  80000 \n",
      "Number of train data with noise:  240000 \n",
      "Number of test data without noise:  20000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in dataset: \", len(data),\n",
    "    \"\\nNumber of records in sample: \", len(X),\n",
    "    \"\\nNumber of train data without noise: \", len(X_train1),\n",
    "    \"\\nNumber of train data with noise: \", len(X_train_n),\n",
    "    \"\\nNumber of test data without noise: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining neural network model architecture\n",
    "    * it is simple combined architecture with 1D CNN and recurrent LSTM layer\n",
    "    * input shape of vector is  400x1, output is array 12x1 - 12 predicted physical parameters\n",
    "    * model will be saved as *norm_detached_all_params.hdf5* in *models* folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 400, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 398, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 199, 64)           33024     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12736)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                815168    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 12)                396       \n",
      "=================================================================\n",
      "Total params: 850,924\n",
      "Trainable params: 850,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(400, 1))\n",
    "b = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs)\n",
    "b = MaxPooling1D(2)(b)\n",
    "b = Dropout(0.2)(b)\n",
    "b = LSTM(64, return_sequences=True)(b)\n",
    "b = Flatten()(b)\n",
    "b = Dense(64, activation='relu')(b)\n",
    "x = Dense(32, activation='relu')(b)\n",
    "output = Dense(12, activation='linear')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mae\", \"mape\"])\n",
    "\n",
    "saved_model = \"models/norm_detached_all_params.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor = 'val_mae', verbose = 1, save_best_only = True, mode = 'min')\n",
    "early = EarlyStopping(monitor = \"val_mae\", mode = \"min\", patience = 25)\n",
    "callbacks_list = [checkpoint, early]\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model training\n",
    "    * Model is trained for 10 epochs\n",
    "    * For validation data set we selected 10% of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0274 - mae: 0.1068 - mape: 5080980.5000\n",
      "Epoch 00001: val_mae improved from inf to 0.09556, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 425s 126ms/step - loss: 0.0274 - mae: 0.1068 - mape: 5080980.5000 - val_loss: 0.0222 - val_mae: 0.0956 - val_mape: 4508048.0000\n",
      "Epoch 2/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0215 - mae: 0.0917 - mape: 4007379.0000\n",
      "Epoch 00002: val_mae improved from 0.09556 to 0.08633, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 408s 121ms/step - loss: 0.0215 - mae: 0.0917 - mape: 4007379.0000 - val_loss: 0.0196 - val_mae: 0.0863 - val_mape: 4008381.7500\n",
      "Epoch 3/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0199 - mae: 0.0868 - mape: 3680181.7500\n",
      "Epoch 00003: val_mae improved from 0.08633 to 0.08368, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 411s 122ms/step - loss: 0.0199 - mae: 0.0868 - mape: 3680181.7500 - val_loss: 0.0186 - val_mae: 0.0837 - val_mape: 3420719.0000\n",
      "Epoch 4/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0188 - mae: 0.0835 - mape: 3501387.0000\n",
      "Epoch 00004: val_mae improved from 0.08368 to 0.07832, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 416s 123ms/step - loss: 0.0188 - mae: 0.0835 - mape: 3501387.0000 - val_loss: 0.0174 - val_mae: 0.0783 - val_mape: 3229455.0000\n",
      "Epoch 5/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0178 - mae: 0.0805 - mape: 3333637.5000\n",
      "Epoch 00005: val_mae improved from 0.07832 to 0.07459, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 404s 120ms/step - loss: 0.0178 - mae: 0.0805 - mape: 3333637.5000 - val_loss: 0.0162 - val_mae: 0.0746 - val_mape: 2972578.2500\n",
      "Epoch 6/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0171 - mae: 0.0779 - mape: 3216459.0000\n",
      "Epoch 00006: val_mae did not improve from 0.07459\n",
      "3375/3375 [==============================] - 408s 121ms/step - loss: 0.0171 - mae: 0.0779 - mape: 3216459.0000 - val_loss: 0.0159 - val_mae: 0.0765 - val_mape: 3444212.7500\n",
      "Epoch 7/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0164 - mae: 0.0759 - mape: 3134341.5000\n",
      "Epoch 00007: val_mae improved from 0.07459 to 0.07284, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 409s 121ms/step - loss: 0.0164 - mae: 0.0759 - mape: 3134341.5000 - val_loss: 0.0155 - val_mae: 0.0728 - val_mape: 3277366.2500\n",
      "Epoch 8/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0160 - mae: 0.0745 - mape: 3065457.7500\n",
      "Epoch 00008: val_mae improved from 0.07284 to 0.07153, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 415s 123ms/step - loss: 0.0160 - mae: 0.0745 - mape: 3065457.7500 - val_loss: 0.0151 - val_mae: 0.0715 - val_mape: 3019149.0000\n",
      "Epoch 9/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0156 - mae: 0.0731 - mape: 3005823.5000\n",
      "Epoch 00009: val_mae improved from 0.07153 to 0.06848, saving model to models\\norm_detached_all_params.hdf5\n",
      "3375/3375 [==============================] - 559s 166ms/step - loss: 0.0156 - mae: 0.0731 - mape: 3005823.5000 - val_loss: 0.0145 - val_mae: 0.0685 - val_mape: 2914808.2500\n",
      "Epoch 10/10\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0153 - mae: 0.0722 - mape: 2940504.5000 ETA: 2s - loss: 0.0153 - \n",
      "Epoch 00010: val_mae did not improve from 0.06848\n",
      "3375/3375 [==============================] - 604s 179ms/step - loss: 0.0153 - mae: 0.0722 - mape: 2940504.5000 - val_loss: 0.0145 - val_mae: 0.0695 - val_mape: 2890226.2500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_n, y_train_n, validation_split = 0.1, epochs = 10, verbose = 1, callbacks = callbacks_list, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"models/norm_detached_all_params.hdf5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model evaluation on test data without added noise\n",
    "* In the output we can see loss and MAE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 40s 65ms/step - loss: 0.0143 - mean_absolute_error: 0.0676 - mean_absolute_percentage_error: 2822210.2500\n",
      "Loss: 0.0143, MAE: 0.0676\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print('Loss: {:.4f}, MAE: {:.4f}'.format(scores[0], scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding random noise to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_n = []\n",
    "y_test_norm_n = []\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(3):\n",
    "        curve = stochastic_noise_generator(X_test[i])\n",
    "        X_test_n.append(curve[0])\n",
    "        y_test_norm_n.append(y_test[i])\n",
    "        j += 1\n",
    "X_test_n = np.array(X_test_n)\n",
    "y_test_norm_n = np.array(y_test_norm_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model evaluation on test data with added noise\n",
    "* In the output we can see loss and MAE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 102s 54ms/step - loss: 0.0149 - mean_absolute_error: 0.0691 - mean_absolute_percentage_error: 2925138.5000\n",
      "Loss: 0.0149, MAE: 0.0691\n"
     ]
    }
   ],
   "source": [
    "scores_n = model.evaluate(X_test_n, y_test_norm_n)\n",
    "print('Loss: {:.4f}, MAE: {:.4f}'.format(scores_n[0], scores_n[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions on test data without noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Predictions on test data without noise\n",
    "* Predictions are saved into *y_pred_norm* variable in the form of multi-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_norm = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since model is predicting normalized values, we need to denormalize array of predictions with use of inverse transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.1713391e+04,  1.7028617e+04,  1.3953224e+00,  1.6369009e+00,\n",
       "        8.6988602e+00,  1.2150850e+01,  1.1674731e+00,  4.5563955e+00,\n",
       "        1.6504228e-01,  1.7309594e-01, -2.1386898e+01, -9.7847910e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denorm = scaler.inverse_transform(y_pred_norm)\n",
    "denorm[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create data frame of denormalized predictions with specific column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_prim__t_eff</th>\n",
       "      <th>P_sec__t_eff</th>\n",
       "      <th>P_inclination</th>\n",
       "      <th>P_mass_ratio</th>\n",
       "      <th>P_prim__surface_potential</th>\n",
       "      <th>P_sec__surface_potential</th>\n",
       "      <th>P_t1_t2</th>\n",
       "      <th>P_critical_surface_potential</th>\n",
       "      <th>P_primary_equivalent_radius</th>\n",
       "      <th>P_secondary_equivalent_radius</th>\n",
       "      <th>P_primary_filling_factor</th>\n",
       "      <th>P_secondary_filling_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21713.390625</td>\n",
       "      <td>17028.617188</td>\n",
       "      <td>1.395322</td>\n",
       "      <td>1.636901</td>\n",
       "      <td>8.698860</td>\n",
       "      <td>12.150850</td>\n",
       "      <td>1.167473</td>\n",
       "      <td>4.556396</td>\n",
       "      <td>0.165042</td>\n",
       "      <td>0.173096</td>\n",
       "      <td>-21.386898</td>\n",
       "      <td>-9.784791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20370.228516</td>\n",
       "      <td>9271.480469</td>\n",
       "      <td>1.432273</td>\n",
       "      <td>1.192739</td>\n",
       "      <td>20.403212</td>\n",
       "      <td>31.860313</td>\n",
       "      <td>2.317413</td>\n",
       "      <td>3.877478</td>\n",
       "      <td>0.108669</td>\n",
       "      <td>0.066830</td>\n",
       "      <td>-57.957951</td>\n",
       "      <td>-66.856216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20484.207031</td>\n",
       "      <td>13641.383789</td>\n",
       "      <td>1.417863</td>\n",
       "      <td>1.242624</td>\n",
       "      <td>2.690766</td>\n",
       "      <td>8.863263</td>\n",
       "      <td>1.412860</td>\n",
       "      <td>4.128850</td>\n",
       "      <td>0.284711</td>\n",
       "      <td>0.271785</td>\n",
       "      <td>2.918470</td>\n",
       "      <td>4.684364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26482.248047</td>\n",
       "      <td>10883.576172</td>\n",
       "      <td>1.366974</td>\n",
       "      <td>1.097659</td>\n",
       "      <td>3.090334</td>\n",
       "      <td>3.780988</td>\n",
       "      <td>2.763849</td>\n",
       "      <td>3.897063</td>\n",
       "      <td>0.320970</td>\n",
       "      <td>0.324458</td>\n",
       "      <td>8.847303</td>\n",
       "      <td>9.564446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28366.121094</td>\n",
       "      <td>7792.821777</td>\n",
       "      <td>1.367452</td>\n",
       "      <td>1.169786</td>\n",
       "      <td>11.709270</td>\n",
       "      <td>15.829687</td>\n",
       "      <td>3.665346</td>\n",
       "      <td>3.899266</td>\n",
       "      <td>0.095586</td>\n",
       "      <td>0.143613</td>\n",
       "      <td>-27.030075</td>\n",
       "      <td>-17.823490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_prim__t_eff  ...  P_secondary_filling_factor\n",
       "0   21713.390625  ...                   -9.784791\n",
       "1   20370.228516  ...                  -66.856216\n",
       "2   20484.207031  ...                    4.684364\n",
       "3   26482.248047  ...                    9.564446\n",
       "4   28366.121094  ...                  -17.823490\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_denorm_df = pd.DataFrame(denorm,\n",
    "                            columns = [\n",
    "                                \"P_prim__t_eff\",\n",
    "                                \"P_sec__t_eff\",\n",
    "                                \"P_inclination\",\n",
    "                                \"P_mass_ratio\",\n",
    "                                \"P_prim__surface_potential\",\n",
    "                                \"P_sec__surface_potential\",\n",
    "                                \"P_t1_t2\",\n",
    "                                \"P_critical_surface_potential\",\n",
    "                                \"P_primary_equivalent_radius\",\n",
    "                                \"P_secondary_equivalent_radius\",\n",
    "                                \"P_primary_filling_factor\",\n",
    "                                \"P_secondary_filling_factor\"\n",
    "                            ])\n",
    "y_pred_denorm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average values for each predicted attribute calculated with *mean()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_prim__t_eff                    21964.074219\n",
       "P_sec__t_eff                      9857.833984\n",
       "P_inclination                        1.369297\n",
       "P_mass_ratio                         1.618292\n",
       "P_prim__surface_potential           17.017254\n",
       "P_sec__surface_potential            17.733107\n",
       "P_t1_t2                              2.610183\n",
       "P_critical_surface_potential         4.525213\n",
       "P_primary_equivalent_radius          0.173925\n",
       "P_secondary_equivalent_radius        0.209024\n",
       "P_primary_filling_factor           -28.454815\n",
       "P_secondary_filling_factor         -20.850000\n",
       "dtype: float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mean = y_pred_denorm_df.mean(axis=0)\n",
    "pred_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data frame created from test datasets\n",
    "* Average values for each attribute is calculated with *mean()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prim__t_eff                    22565.200000\n",
       "sec__t_eff                     10129.450000\n",
       "inclination                        1.375910\n",
       "mass_ratio                         1.747564\n",
       "prim__surface_potential           18.126015\n",
       "sec__surface_potential            16.289401\n",
       "t1_t2                              2.675162\n",
       "critical_surface_potential         4.666303\n",
       "primary_equivalent_radius          0.176560\n",
       "secondary_equivalent_radius        0.200172\n",
       "primary_filling_factor           -34.399594\n",
       "secondary_filling_factor         -23.618069\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denorm_test = scaler.inverse_transform(y_test)\n",
    "y_test_norm_df = pd.DataFrame(denorm_test,\n",
    "                            columns = [\n",
    "                                \"prim__t_eff\",\n",
    "                                \"sec__t_eff\",\n",
    "                                \"inclination\",\n",
    "                                \"mass_ratio\",\n",
    "                                \"prim__surface_potential\",\n",
    "                                \"sec__surface_potential\",\n",
    "                                \"t1_t2\",\n",
    "                                \"critical_surface_potential\",\n",
    "                                \"primary_equivalent_radius\",\n",
    "                                \"secondary_equivalent_radius\",\n",
    "                                \"primary_filling_factor\",\n",
    "                                \"secondary_filling_factor\"\n",
    "                            ])\n",
    "true_mean = y_test_norm_df.mean(axis=0)\n",
    "true_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dataframe created for purpose to compare average true and predicted value, with Mean Average Error showed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>avg_true</th>\n",
       "      <th>avg_pred</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prim__t_eff</td>\n",
       "      <td>22565.200000</td>\n",
       "      <td>21964.074219</td>\n",
       "      <td>601.125781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sec__t_eff</td>\n",
       "      <td>10129.450000</td>\n",
       "      <td>9857.833984</td>\n",
       "      <td>271.616016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inclination</td>\n",
       "      <td>1.375910</td>\n",
       "      <td>1.369297</td>\n",
       "      <td>0.006613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mass_ratio</td>\n",
       "      <td>1.747564</td>\n",
       "      <td>1.618292</td>\n",
       "      <td>0.129272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prim__surface_potential</td>\n",
       "      <td>18.126015</td>\n",
       "      <td>17.017254</td>\n",
       "      <td>1.108761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sec__surface_potential</td>\n",
       "      <td>16.289401</td>\n",
       "      <td>17.733107</td>\n",
       "      <td>1.443706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t1_t2</td>\n",
       "      <td>2.675162</td>\n",
       "      <td>2.610183</td>\n",
       "      <td>0.064979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>critical_surface_potential</td>\n",
       "      <td>4.666303</td>\n",
       "      <td>4.525213</td>\n",
       "      <td>0.141090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>primary_equivalent_radius</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.173925</td>\n",
       "      <td>0.002635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>secondary_equivalent_radius</td>\n",
       "      <td>0.200172</td>\n",
       "      <td>0.209024</td>\n",
       "      <td>0.008852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>primary_filling_factor</td>\n",
       "      <td>-34.399594</td>\n",
       "      <td>-28.454815</td>\n",
       "      <td>5.944779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>secondary_filling_factor</td>\n",
       "      <td>-23.618069</td>\n",
       "      <td>-20.850000</td>\n",
       "      <td>2.768068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      attribute      avg_true      avg_pred         MAE\n",
       "0                   prim__t_eff  22565.200000  21964.074219  601.125781\n",
       "1                    sec__t_eff  10129.450000   9857.833984  271.616016\n",
       "2                   inclination      1.375910      1.369297    0.006613\n",
       "3                    mass_ratio      1.747564      1.618292    0.129272\n",
       "4       prim__surface_potential     18.126015     17.017254    1.108761\n",
       "5        sec__surface_potential     16.289401     17.733107    1.443706\n",
       "6                         t1_t2      2.675162      2.610183    0.064979\n",
       "7    critical_surface_potential      4.666303      4.525213    0.141090\n",
       "8     primary_equivalent_radius      0.176560      0.173925    0.002635\n",
       "9   secondary_equivalent_radius      0.200172      0.209024    0.008852\n",
       "10       primary_filling_factor    -34.399594    -28.454815    5.944779\n",
       "11     secondary_filling_factor    -23.618069    -20.850000    2.768068"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pred = pd.DataFrame({'attribute': true_mean.index,\n",
    "            'avg_true': true_mean.values,\n",
    "            'avg_pred': pred_mean.values,\n",
    "            'MAE': abs(true_mean.values - pred_mean.values)})\n",
    "eval_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction on test data with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prediction on test data with noise\n",
    "* Predictions are save into *y_pred_norm_n* variable in the form of multi-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_norm_n = model.predict(X_test_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since model is predicting normalized values, we need to denormalize array of predictions with use of inverse transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.3069885e+04,  1.7985830e+04,  1.3949709e+00,  1.7647982e+00,\n",
       "        9.1150284e+00,  1.2332879e+01,  1.1173550e+00,  4.7598162e+00,\n",
       "        1.5445419e-01,  1.7978655e-01, -2.1069891e+01, -8.1847010e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denorm_n = scaler.inverse_transform(y_pred_norm_n)\n",
    "denorm_n[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create data frame of denormalized predictions with specific column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_prim__t_eff</th>\n",
       "      <th>P_sec__t_eff</th>\n",
       "      <th>P_inclination</th>\n",
       "      <th>P_mass_ratio</th>\n",
       "      <th>P_prim__surface_potential</th>\n",
       "      <th>P_sec__surface_potential</th>\n",
       "      <th>P_t1_t2</th>\n",
       "      <th>P_critical_surface_potential</th>\n",
       "      <th>P_primary_equivalent_radius</th>\n",
       "      <th>P_secondary_equivalent_radius</th>\n",
       "      <th>P_primary_filling_factor</th>\n",
       "      <th>P_secondary_filling_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23069.884766</td>\n",
       "      <td>17985.830078</td>\n",
       "      <td>1.394971</td>\n",
       "      <td>1.764798</td>\n",
       "      <td>9.115028</td>\n",
       "      <td>12.332879</td>\n",
       "      <td>1.117355</td>\n",
       "      <td>4.759816</td>\n",
       "      <td>0.154454</td>\n",
       "      <td>0.179787</td>\n",
       "      <td>-21.069891</td>\n",
       "      <td>-8.184701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21730.755859</td>\n",
       "      <td>17053.150391</td>\n",
       "      <td>1.394916</td>\n",
       "      <td>1.641296</td>\n",
       "      <td>8.711674</td>\n",
       "      <td>12.138206</td>\n",
       "      <td>1.167700</td>\n",
       "      <td>4.561847</td>\n",
       "      <td>0.164768</td>\n",
       "      <td>0.173658</td>\n",
       "      <td>-21.355547</td>\n",
       "      <td>-9.754962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22437.886719</td>\n",
       "      <td>17392.103516</td>\n",
       "      <td>1.406102</td>\n",
       "      <td>1.690352</td>\n",
       "      <td>9.202767</td>\n",
       "      <td>14.912174</td>\n",
       "      <td>1.154073</td>\n",
       "      <td>4.652238</td>\n",
       "      <td>0.157752</td>\n",
       "      <td>0.171174</td>\n",
       "      <td>-21.776283</td>\n",
       "      <td>-12.940541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18172.566406</td>\n",
       "      <td>9790.380859</td>\n",
       "      <td>1.408084</td>\n",
       "      <td>1.414821</td>\n",
       "      <td>12.439978</td>\n",
       "      <td>30.931646</td>\n",
       "      <td>2.002754</td>\n",
       "      <td>4.234660</td>\n",
       "      <td>0.120293</td>\n",
       "      <td>0.077331</td>\n",
       "      <td>-40.354721</td>\n",
       "      <td>-63.336521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20089.316406</td>\n",
       "      <td>10899.501953</td>\n",
       "      <td>1.352746</td>\n",
       "      <td>1.216016</td>\n",
       "      <td>14.105429</td>\n",
       "      <td>27.077154</td>\n",
       "      <td>1.836332</td>\n",
       "      <td>4.010816</td>\n",
       "      <td>0.115363</td>\n",
       "      <td>0.106150</td>\n",
       "      <td>-47.517998</td>\n",
       "      <td>-56.508617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_prim__t_eff  ...  P_secondary_filling_factor\n",
       "0   23069.884766  ...                   -8.184701\n",
       "1   21730.755859  ...                   -9.754962\n",
       "2   22437.886719  ...                  -12.940541\n",
       "3   18172.566406  ...                  -63.336521\n",
       "4   20089.316406  ...                  -56.508617\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_denorm_n_df = pd.DataFrame(denorm_n,\n",
    "                            columns = [\n",
    "                                \"P_prim__t_eff\",\n",
    "                                \"P_sec__t_eff\",\n",
    "                                \"P_inclination\",\n",
    "                                \"P_mass_ratio\",\n",
    "                                \"P_prim__surface_potential\",\n",
    "                                \"P_sec__surface_potential\",\n",
    "                                \"P_t1_t2\",\n",
    "                                \"P_critical_surface_potential\",\n",
    "                                \"P_primary_equivalent_radius\",\n",
    "                                \"P_secondary_equivalent_radius\",\n",
    "                                \"P_primary_filling_factor\",\n",
    "                                \"P_secondary_filling_factor\"\n",
    "                            ])\n",
    "y_pred_denorm_n_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average values for each predicted attribute calculated with *mean()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "P_prim__t_eff                    22021.871094\n",
       "P_sec__t_eff                      9883.876953\n",
       "P_inclination                        1.369198\n",
       "P_mass_ratio                         1.614515\n",
       "P_prim__surface_potential           17.051184\n",
       "P_sec__surface_potential            17.807707\n",
       "P_t1_t2                              2.608001\n",
       "P_critical_surface_potential         4.520045\n",
       "P_primary_equivalent_radius          0.173390\n",
       "P_secondary_equivalent_radius        0.209630\n",
       "P_primary_filling_factor           -28.575169\n",
       "P_secondary_filling_factor         -20.845806\n",
       "dtype: float32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pred_mean = y_pred_denorm_n_df.mean(axis=0)\n",
    "n_pred_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create dataframe of denormalized test values\n",
    "* Calculate average values of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prim__t_eff                    22565.200000\n",
       "sec__t_eff                     10129.450000\n",
       "inclination                        1.375910\n",
       "mass_ratio                         1.747564\n",
       "prim__surface_potential           18.126015\n",
       "sec__surface_potential            16.289401\n",
       "t1_t2                              2.675162\n",
       "critical_surface_potential         4.666303\n",
       "primary_equivalent_radius          0.176560\n",
       "secondary_equivalent_radius        0.200172\n",
       "primary_filling_factor           -34.399594\n",
       "secondary_filling_factor         -23.618069\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denorm_test_n = scaler.inverse_transform(y_test_norm_n)\n",
    "y_test_norm_df_n = pd.DataFrame(denorm_test_n,\n",
    "                            columns = [\n",
    "                                \"prim__t_eff\",\n",
    "                                \"sec__t_eff\",\n",
    "                                \"inclination\",\n",
    "                                \"mass_ratio\",\n",
    "                                \"prim__surface_potential\",\n",
    "                                \"sec__surface_potential\",\n",
    "                                \"t1_t2\",\n",
    "                                \"critical_surface_potential\",\n",
    "                                \"primary_equivalent_radius\",\n",
    "                                \"secondary_equivalent_radius\",\n",
    "                                \"primary_filling_factor\",\n",
    "                                \"secondary_filling_factor\"\n",
    "                            ])\n",
    "true_mean = y_test_norm_df_n.mean(axis=0)\n",
    "true_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dataframe created for purpose to compare average true and predicted value, with Mean Average Error showed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>avg_true</th>\n",
       "      <th>avg_pred</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prim__t_eff</td>\n",
       "      <td>22565.200000</td>\n",
       "      <td>22021.871094</td>\n",
       "      <td>543.328906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sec__t_eff</td>\n",
       "      <td>10129.450000</td>\n",
       "      <td>9883.876953</td>\n",
       "      <td>245.573047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inclination</td>\n",
       "      <td>1.375910</td>\n",
       "      <td>1.369198</td>\n",
       "      <td>0.006712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mass_ratio</td>\n",
       "      <td>1.747564</td>\n",
       "      <td>1.614515</td>\n",
       "      <td>0.133050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prim__surface_potential</td>\n",
       "      <td>18.126015</td>\n",
       "      <td>17.051184</td>\n",
       "      <td>1.074831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sec__surface_potential</td>\n",
       "      <td>16.289401</td>\n",
       "      <td>17.807707</td>\n",
       "      <td>1.518306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t1_t2</td>\n",
       "      <td>2.675162</td>\n",
       "      <td>2.608001</td>\n",
       "      <td>0.067161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>critical_surface_potential</td>\n",
       "      <td>4.666303</td>\n",
       "      <td>4.520045</td>\n",
       "      <td>0.146258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>primary_equivalent_radius</td>\n",
       "      <td>0.176560</td>\n",
       "      <td>0.173390</td>\n",
       "      <td>0.003171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>secondary_equivalent_radius</td>\n",
       "      <td>0.200172</td>\n",
       "      <td>0.209630</td>\n",
       "      <td>0.009458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>primary_filling_factor</td>\n",
       "      <td>-34.399594</td>\n",
       "      <td>-28.575169</td>\n",
       "      <td>5.824426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>secondary_filling_factor</td>\n",
       "      <td>-23.618069</td>\n",
       "      <td>-20.845806</td>\n",
       "      <td>2.772262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      attribute      avg_true      avg_pred         MAE\n",
       "0                   prim__t_eff  22565.200000  22021.871094  543.328906\n",
       "1                    sec__t_eff  10129.450000   9883.876953  245.573047\n",
       "2                   inclination      1.375910      1.369198    0.006712\n",
       "3                    mass_ratio      1.747564      1.614515    0.133050\n",
       "4       prim__surface_potential     18.126015     17.051184    1.074831\n",
       "5        sec__surface_potential     16.289401     17.807707    1.518306\n",
       "6                         t1_t2      2.675162      2.608001    0.067161\n",
       "7    critical_surface_potential      4.666303      4.520045    0.146258\n",
       "8     primary_equivalent_radius      0.176560      0.173390    0.003171\n",
       "9   secondary_equivalent_radius      0.200172      0.209630    0.009458\n",
       "10       primary_filling_factor    -34.399594    -28.575169    5.824426\n",
       "11     secondary_filling_factor    -23.618069    -20.845806    2.772262"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_eval_pred = pd.DataFrame({'attribute': true_mean.index,\n",
    "            'avg_true': true_mean.values,\n",
    "            'avg_pred': n_pred_mean.values,\n",
    "            'MAE': abs(true_mean.values - n_pred_mean.values)})\n",
    "n_eval_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('global')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8fc6ce4f931e35f5dd2ff00f5d2ede33ff85432a244cf6e3e9d498f6426f487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
