{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of selected physical parameters of over-contact data with simple combined NN model\n",
    "In this Jupyter Notebook we will train NN model to predict selected physical parameter of over-contact binary systems. Content:\n",
    "* Libraries, functions\n",
    "* Data preparation\n",
    "* Create architecture of NN model\n",
    "* Evaluation of model\n",
    "* Predictions\n",
    "* Evaluation of predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment set-up\n",
    "* Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import Input, Dense, LSTM, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "np.random.seed(1234)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining functions for noise generation, set-up of random sigma value generator.\n",
    "* Inputs:\n",
    "    * for function generate_observation_sigma(space_obs_frac=0.5) - space_obs_frac=0.5\n",
    "    * for function stochastic_noise_generator(curve) - vector of light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_observation_sigma(space_obs_frac=0.5):\n",
    "    \"\"\"\n",
    "    Draws a standard deviation of noise in light curve points from a \"true\" value provided in synthetic light curve.\n",
    "    Noise sigma is drawn from bimodal distribution taking into account contributions from space based and earth based\n",
    "    observations which have different levels of stochastic noise.\n",
    "\n",
    "    :param space_obs_frac: ratio between earth based and space based observations\n",
    "    :return: float; standard deviation of the light curve noise\n",
    "    \"\"\"\n",
    "    earth_based_sigma = 4e-3\n",
    "    space_based_sigma = 2e-4\n",
    "    sigma = np.random.choice([earth_based_sigma, space_based_sigma], p=[1-space_obs_frac, space_obs_frac])\n",
    "    return np.random.rayleigh(sigma)\n",
    "\n",
    "def stochastic_noise_generator(curve):\n",
    "    \"\"\"\n",
    "    Introduces gaussian noise into synthetic observation provided in `curve`.\n",
    "\n",
    "    :param curve: numpy.array; normalized light curve\n",
    "    :return: Tuple(numpy.array, float); normalized light curve with added noise, standard deviation of observations\n",
    "    \"\"\"\n",
    "    sigma = generate_observation_sigma()\n",
    "    return np.random.normal(curve, sigma), np.full(curve.shape, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data loading\n",
    "* Loading synthetic data from .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"overcontact_all_parameters.pkl\").reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Selecting random sample of data of size 300 000 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(n=300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create multi-dimensional array of vectors of light curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for row in data_sample[\"curve\"]:\n",
    "    X.append(row)\n",
    "X=np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create array of features, which will model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data_sample[[\n",
    "    \"inclination\",\n",
    "    \"mass_ratio\",\n",
    "    \"primary__surface_potential\",\n",
    "    \"secondary__surface_potential\",\n",
    "    \"t1/t2\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining MinMax scaler object\n",
    "* Fitting scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79148929, 0.49494949, 0.53031622, 0.53031622, 0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "y_minmax_scaled = scaler.fit_transform(y)\n",
    "y_minmax_scaled[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Splitting data into training and testing data sets in 80:20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test, y_train1, y_test = train_test_split(X, y_minmax_scaled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding noise into training datasets (noise generated with functions defined earlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n = []\n",
    "y_train_n = []\n",
    "for i in range(len(X_train1)):\n",
    "    for j in range(3):\n",
    "        curve = stochastic_noise_generator(X_train1[i])\n",
    "        X_train_n.append(curve[0])\n",
    "        y_train_n.append(y_train1[i])\n",
    "X_train_n = np.array(X_train_n)\n",
    "y_train_n=np.array(y_train_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Details about number of records in specific data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in dataset:  1212796 \n",
      "Number of records in sample:  300000 \n",
      "Number of train data without noise:  240000 \n",
      "Number of train data with noise:  720000 \n",
      "Number of test data without noise:  60000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of records in dataset: \", len(data),\n",
    "    \"\\nNumber of records in sample: \", len(X),\n",
    "    \"\\nNumber of train data without noise: \", len(X_train1),\n",
    "    \"\\nNumber of train data with noise: \", len(X_train_n),\n",
    "    \"\\nNumber of test data without noise: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Defining neural network model architecture\n",
    "    * it is simple combined architecture with 1D CNN and recurrent LSTM layer\n",
    "    * input shape of vector is  400x1, outpot is array 10x1 - 10 predicted physical parameters\n",
    "    * model will be saved as *norm_overcontact_selection.hdf5* in *models* folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 400, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 398, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 199, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 199, 64)           33024     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12736)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                815168    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 850,693\n",
      "Trainable params: 850,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(400, 1))\n",
    "b = Conv1D(64, kernel_size = 3, padding = \"valid\")(inputs)\n",
    "b = MaxPooling1D(2)(b)\n",
    "b = Dropout(0.2)(b)\n",
    "b = LSTM(64, return_sequences=True)(b)\n",
    "b = Flatten()(b)\n",
    "b = Dense(64, activation='relu')(b)\n",
    "x = Dense(32, activation='relu')(b)\n",
    "output = Dense(5, activation='linear')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='mse', optimizer='adam', metrics=[\"mae\", \"mape\"])\n",
    "\n",
    "saved_model = \"models/norm_overcontact_selection.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor = 'val_mae', verbose = 1, save_best_only = True, mode = 'min')\n",
    "early = EarlyStopping(monitor = \"val_mae\", mode = \"min\", patience = 25)\n",
    "callbacks_list = [checkpoint, early]\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model training\n",
    "    * Model is trained for 10 epochs\n",
    "    * For validation data set we selected 10% of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0102 - mae: 0.0602 - mape: 7245895.0000\n",
      "Epoch 00001: val_mae improved from inf to 0.04150, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1669s 165ms/step - loss: 0.0102 - mae: 0.0602 - mape: 7245895.0000 - val_loss: 0.0056 - val_mae: 0.0415 - val_mape: 5226817.5000\n",
      "Epoch 2/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0063 - mae: 0.0459 - mape: 5063508.5000\n",
      "Epoch 00002: val_mae improved from 0.04150 to 0.03797, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1461s 144ms/step - loss: 0.0063 - mae: 0.0459 - mape: 5063508.5000 - val_loss: 0.0048 - val_mae: 0.0380 - val_mape: 4130595.2500\n",
      "Epoch 3/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0058 - mae: 0.0430 - mape: 4662523.5000\n",
      "Epoch 00003: val_mae improved from 0.03797 to 0.03612, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1197s 118ms/step - loss: 0.0058 - mae: 0.0430 - mape: 4662523.5000 - val_loss: 0.0047 - val_mae: 0.0361 - val_mape: 3429707.7500\n",
      "Epoch 4/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0055 - mae: 0.0413 - mape: 4466712.0000\n",
      "Epoch 00004: val_mae did not improve from 0.03612\n",
      "10125/10125 [==============================] - 1207s 119ms/step - loss: 0.0055 - mae: 0.0413 - mape: 4466712.0000 - val_loss: 0.0045 - val_mae: 0.0378 - val_mape: 4276660.0000\n",
      "Epoch 5/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0052 - mae: 0.0400 - mape: 4336098.0000\n",
      "Epoch 00005: val_mae improved from 0.03612 to 0.03433, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1271s 126ms/step - loss: 0.0052 - mae: 0.0400 - mape: 4336098.0000 - val_loss: 0.0043 - val_mae: 0.0343 - val_mape: 3821489.7500\n",
      "Epoch 6/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0050 - mae: 0.0389 - mape: 4197752.5000\n",
      "Epoch 00006: val_mae did not improve from 0.03433\n",
      "10125/10125 [==============================] - 1252s 124ms/step - loss: 0.0050 - mae: 0.0389 - mape: 4197752.5000 - val_loss: 0.0042 - val_mae: 0.0349 - val_mape: 3935021.2500\n",
      "Epoch 7/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0049 - mae: 0.0382 - mape: 4117690.0000\n",
      "Epoch 00007: val_mae improved from 0.03433 to 0.03414, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1265s 125ms/step - loss: 0.0049 - mae: 0.0382 - mape: 4117690.0000 - val_loss: 0.0041 - val_mae: 0.0341 - val_mape: 4133843.5000\n",
      "Epoch 8/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0048 - mae: 0.0376 - mape: 4034764.7500\n",
      "Epoch 00008: val_mae did not improve from 0.03414\n",
      "10125/10125 [==============================] - 1270s 125ms/step - loss: 0.0048 - mae: 0.0376 - mape: 4034764.7500 - val_loss: 0.0044 - val_mae: 0.0377 - val_mape: 3248022.7500\n",
      "Epoch 9/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0047 - mae: 0.0371 - mape: 3935298.0000\n",
      "Epoch 00009: val_mae did not improve from 0.03414\n",
      "10125/10125 [==============================] - 1253s 124ms/step - loss: 0.0047 - mae: 0.0371 - mape: 3935298.0000 - val_loss: 0.0040 - val_mae: 0.0343 - val_mape: 3873350.0000\n",
      "Epoch 10/10\n",
      "10125/10125 [==============================] - ETA: 0s - loss: 0.0046 - mae: 0.0367 - mape: 3882957.5000\n",
      "Epoch 00010: val_mae improved from 0.03414 to 0.03358, saving model to models\\norm_overcontact_selection.hdf5\n",
      "10125/10125 [==============================] - 1268s 125ms/step - loss: 0.0046 - mae: 0.0367 - mape: 3882957.5000 - val_loss: 0.0040 - val_mae: 0.0336 - val_mape: 2996968.2500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_n, y_train_n, validation_split = 0.1, epochs = 10, verbose = 1, callbacks = callbacks_list, batch_size = 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"models/norm_overcontact_selection.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model evaluation on test data without added noise\n",
    "* In the output we can see loss and MAE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 82s 44ms/step - loss: 0.0038 - mean_absolute_error: 0.0322 - mean_absolute_percentage_error: 2902031.5000\n",
      "Loss: 0.0038, MAE: 0.0322\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print('Loss: {:.4f}, MAE: {:.4f}'.format(scores[0], scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding random noise to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_n = []\n",
    "y_test_norm_n = []\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(3):\n",
    "        curve = stochastic_noise_generator(X_test[i])\n",
    "        X_test_n.append(curve[0])\n",
    "        y_test_norm_n.append(y_test[i])\n",
    "        j += 1\n",
    "X_test_n = np.array(X_test_n)\n",
    "y_test_norm_n = np.array(y_test_norm_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model evaluation on test data with added noise\n",
    "* In the output we can see loss and MAE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 514s 91ms/step - loss: 0.0040 - mean_absolute_error: 0.0336 - mean_absolute_percentage_error: 3030820.2500s - loss: 0.0040 - mean_absolute_er\n",
      "Loss: 0.0040, MAE: 0.0336\n"
     ]
    }
   ],
   "source": [
    "scores_n = model.evaluate(X_test_n, y_test_norm_n)\n",
    "print('Loss: {:.4f}, MAE: {:.4f}'.format(scores_n[0], scores_n[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions on test data without noise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Predictions on test data without noise\n",
    "* Predictions are saved into *y_pred_norm* variable in the form of multi-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_norm = model.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since model is predicting normalized values, we need to denormalize array of predictions with use of inverse transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00987  , 1.2422509, 3.814539 , 3.813457 , 1.0802377],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denorm = scaler.inverse_transform(y_pred_norm)\n",
    "denorm[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create data frame of denormalized predictions with specific column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inclination</th>\n",
       "      <th>mass_ratio</th>\n",
       "      <th>primary__surface_potential</th>\n",
       "      <th>secondary__surface_potential</th>\n",
       "      <th>t1_t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.009870</td>\n",
       "      <td>1.242251</td>\n",
       "      <td>3.814539</td>\n",
       "      <td>3.813457</td>\n",
       "      <td>1.080238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.434893</td>\n",
       "      <td>0.897172</td>\n",
       "      <td>3.358399</td>\n",
       "      <td>3.383627</td>\n",
       "      <td>1.033528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.009152</td>\n",
       "      <td>0.991710</td>\n",
       "      <td>3.349905</td>\n",
       "      <td>3.248664</td>\n",
       "      <td>1.077547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.329317</td>\n",
       "      <td>0.905684</td>\n",
       "      <td>3.490230</td>\n",
       "      <td>3.525199</td>\n",
       "      <td>1.076381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.887441</td>\n",
       "      <td>0.914283</td>\n",
       "      <td>3.264172</td>\n",
       "      <td>3.233231</td>\n",
       "      <td>1.063057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inclination  mass_ratio  primary__surface_potential  \\\n",
       "0     1.009870    1.242251                    3.814539   \n",
       "1     1.434893    0.897172                    3.358399   \n",
       "2     1.009152    0.991710                    3.349905   \n",
       "3     1.329317    0.905684                    3.490230   \n",
       "4     0.887441    0.914283                    3.264172   \n",
       "\n",
       "   secondary__surface_potential     t1_t2  \n",
       "0                      3.813457  1.080238  \n",
       "1                      3.383627  1.033528  \n",
       "2                      3.248664  1.077547  \n",
       "3                      3.525199  1.076381  \n",
       "4                      3.233231  1.063057  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denorm_pred_df = pd.DataFrame(denorm,\n",
    "                           columns = [\n",
    "                                \"inclination\",\n",
    "                                \"mass_ratio\",\n",
    "                                \"primary__surface_potential\",\n",
    "                                \"secondary__surface_potential\",\n",
    "                                \"t1_t2\"\n",
    "                            ])\n",
    "denorm_pred_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average values for each predicted attribute calculated with *mean()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inclination                     1.207262\n",
       "mass_ratio                      1.460771\n",
       "primary__surface_potential      4.067463\n",
       "secondary__surface_potential    4.059316\n",
       "t1_t2                           1.045363\n",
       "dtype: float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_mean = denorm_pred_df.mean(axis=0)\n",
    "pred_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data frame created from test datasets\n",
    "* Average values for each attribute is calculated with *mean()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inclination                     1.222845\n",
       "mass_ratio                      1.422204\n",
       "primary__surface_potential      3.987477\n",
       "secondary__surface_potential    3.987477\n",
       "t1_t2                           1.048233\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_df = pd.DataFrame(y,\n",
    "                        columns = [\n",
    "                            \"inclination\",\n",
    "                            \"mass_ratio\",\n",
    "                            \"primary__surface_potential\",\n",
    "                            \"secondary__surface_potential\",\n",
    "                            \"t1_t2\"\n",
    "                            ])\n",
    "test_mean = y_test_df.mean(axis=0)\n",
    "test_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dataframe created for purpose to compare average true and predicted value, with Mean Average Error showed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>avg_true</th>\n",
       "      <th>avg_pred</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inclination</td>\n",
       "      <td>1.222845</td>\n",
       "      <td>1.207262</td>\n",
       "      <td>0.015583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mass_ratio</td>\n",
       "      <td>1.422204</td>\n",
       "      <td>1.460771</td>\n",
       "      <td>0.038567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>primary__surface_potential</td>\n",
       "      <td>3.987477</td>\n",
       "      <td>4.067463</td>\n",
       "      <td>0.079986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>secondary__surface_potential</td>\n",
       "      <td>3.987477</td>\n",
       "      <td>4.059316</td>\n",
       "      <td>0.071839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_t2</td>\n",
       "      <td>1.048233</td>\n",
       "      <td>1.045363</td>\n",
       "      <td>0.002869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      attribute  avg_true  avg_pred       MAE\n",
       "0                   inclination  1.222845  1.207262  0.015583\n",
       "1                    mass_ratio  1.422204  1.460771  0.038567\n",
       "2    primary__surface_potential  3.987477  4.067463  0.079986\n",
       "3  secondary__surface_potential  3.987477  4.059316  0.071839\n",
       "4                         t1_t2  1.048233  1.045363  0.002869"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pred = pd.DataFrame({'attribute': test_mean.index,\n",
    "            'avg_true': test_mean.values,\n",
    "            'avg_pred': pred_mean.values,\n",
    "            'MAE': abs(test_mean.values - pred_mean.values)})\n",
    "eval_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction on test data with noise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prediction on test data with noise\n",
    "* Predictions are save into *y_pred_norm_n* variable in the form of multi-dimensional array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_norm_n = model.predict(X_test_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since model is predicting normalized values, we need to denormalize array of predictions with use of inverse transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0137995, 1.2389269, 3.8086123, 3.8100085, 1.0807337],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denorm_n = scaler.inverse_transform(y_pred_norm_n)\n",
    "denorm_n[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create data frame of denormalized predictions with specific column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inclination</th>\n",
       "      <th>mass_ratio</th>\n",
       "      <th>primary__surface_potential</th>\n",
       "      <th>secondary__surface_potential</th>\n",
       "      <th>t1_t2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.013800</td>\n",
       "      <td>1.238927</td>\n",
       "      <td>3.808612</td>\n",
       "      <td>3.810009</td>\n",
       "      <td>1.080734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.009084</td>\n",
       "      <td>1.247791</td>\n",
       "      <td>3.822558</td>\n",
       "      <td>3.821386</td>\n",
       "      <td>1.079962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.010949</td>\n",
       "      <td>1.236768</td>\n",
       "      <td>3.806676</td>\n",
       "      <td>3.805421</td>\n",
       "      <td>1.079818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.434906</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>3.361198</td>\n",
       "      <td>3.386827</td>\n",
       "      <td>1.033581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.435269</td>\n",
       "      <td>0.872110</td>\n",
       "      <td>3.324525</td>\n",
       "      <td>3.346521</td>\n",
       "      <td>1.032596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inclination  mass_ratio  primary__surface_potential  \\\n",
       "0     1.013800    1.238927                    3.808612   \n",
       "1     1.009084    1.247791                    3.822558   \n",
       "2     1.010949    1.236768                    3.806676   \n",
       "3     1.434906    0.899390                    3.361198   \n",
       "4     1.435269    0.872110                    3.324525   \n",
       "\n",
       "   secondary__surface_potential     t1_t2  \n",
       "0                      3.810009  1.080734  \n",
       "1                      3.821386  1.079962  \n",
       "2                      3.805421  1.079818  \n",
       "3                      3.386827  1.033581  \n",
       "4                      3.346521  1.032596  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denorm_pred_n_df = pd.DataFrame(denorm_n,\n",
    "                            columns = [\n",
    "                                \"inclination\",\n",
    "                                \"mass_ratio\",\n",
    "                                \"primary__surface_potential\",\n",
    "                                \"secondary__surface_potential\",\n",
    "                                \"t1_t2\"\n",
    "                            ])\n",
    "denorm_pred_n_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average values for each predicted attribute calculated with *mean()* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inclination                     1.207670\n",
       "mass_ratio                      1.463276\n",
       "primary__surface_potential      4.071081\n",
       "secondary__surface_potential    4.063103\n",
       "t1_t2                           1.045390\n",
       "dtype: float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_n_mean = denorm_pred_n_df.mean(axis=0)\n",
    "pred_n_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We create dataframe of denormalized test values\n",
    "* Calculate average values of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inclination                     1.223116\n",
       "mass_ratio                      1.434141\n",
       "primary__surface_potential      4.002988\n",
       "secondary__surface_potential    4.002988\n",
       "t1_t2                           1.048256\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_n_denorm = scaler.inverse_transform(y_test_norm_n)\n",
    "y_test_norm_n_df = pd.DataFrame(y_test_n_denorm,\n",
    "                            columns = [\n",
    "                            \"inclination\",\n",
    "                            \"mass_ratio\",\n",
    "                            \"primary__surface_potential\",\n",
    "                            \"secondary__surface_potential\",\n",
    "                            \"t1_t2\"\n",
    "                            ])\n",
    "test_mean_n = y_test_norm_n_df.mean(axis=0)\n",
    "test_mean_n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dataframe created for purpose to compare average true and predicted value, with Mean Average Error showed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attribute</th>\n",
       "      <th>avg_true</th>\n",
       "      <th>avg_pred</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inclination</td>\n",
       "      <td>1.223116</td>\n",
       "      <td>1.207670</td>\n",
       "      <td>0.015446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mass_ratio</td>\n",
       "      <td>1.434141</td>\n",
       "      <td>1.463276</td>\n",
       "      <td>0.029135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>primary__surface_potential</td>\n",
       "      <td>4.002988</td>\n",
       "      <td>4.071081</td>\n",
       "      <td>0.068094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>secondary__surface_potential</td>\n",
       "      <td>4.002988</td>\n",
       "      <td>4.063103</td>\n",
       "      <td>0.060115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t1_t2</td>\n",
       "      <td>1.048256</td>\n",
       "      <td>1.045390</td>\n",
       "      <td>0.002866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      attribute  avg_true  avg_pred       MAE\n",
       "0                   inclination  1.223116  1.207670  0.015446\n",
       "1                    mass_ratio  1.434141  1.463276  0.029135\n",
       "2    primary__surface_potential  4.002988  4.071081  0.068094\n",
       "3  secondary__surface_potential  4.002988  4.063103  0.060115\n",
       "4                         t1_t2  1.048256  1.045390  0.002866"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pred = pd.DataFrame({'attribute': test_mean_n.index,\n",
    "            'avg_true': test_mean_n.values,\n",
    "            'avg_pred': pred_n_mean.values,\n",
    "            'MAE': abs(test_mean_n.values - pred_n_mean.values)})\n",
    "eval_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('global')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8fc6ce4f931e35f5dd2ff00f5d2ede33ff85432a244cf6e3e9d498f6426f487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
